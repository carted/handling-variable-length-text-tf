{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f943bf42",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9014279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import wandb\n",
    "import random\n",
    "import time\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44377fcf",
   "metadata": {},
   "source": [
    "## Contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d42dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS_DIR = \"gs://variable-length-sequences-tf/tfrecords-sentence-splitter\"\n",
    "BERT_MAX_SEQLEN = 512\n",
    "BERT_DIM = 768\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 5\n",
    "NUM_RUNS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126bde2",
   "metadata": {},
   "source": [
    "## TFRecord parsing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a40156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = {\n",
    "    \"summary\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_tokens\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_sentence_indices\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_num_sentences\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "    \"summary_tokens_len\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"label\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a5de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_composite(\n",
    "    serialized: bytes, type_spec: tf.RaggedTensorSpec\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Deserializes a serialised ragged tensor.\"\"\"\n",
    "\n",
    "    serialized = tf.io.parse_tensor(serialized, tf.string)\n",
    "    component_specs = tf.nest.flatten(type_spec, expand_composites=True)\n",
    "    components = [\n",
    "        tf.io.parse_tensor(serialized[i], spec.dtype)\n",
    "        for i, spec in enumerate(component_specs)\n",
    "    ]\n",
    "    return tf.nest.pack_sequence_as(type_spec, components, expand_composites=True)\n",
    "\n",
    "\n",
    "def read_example(example):\n",
    "    \"\"\"Parses a single TFRecord file.\"\"\"\n",
    "    features = tf.io.parse_single_example(example, feature_descriptions)\n",
    "    features[\"summary_tokens\"] = deserialize_composite(\n",
    "        features.get(\"summary_tokens\"),\n",
    "        tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=2),\n",
    "    )\n",
    "    features[\"summary_sentence_indices\"] = deserialize_composite(\n",
    "        features.get(\"summary_sentence_indices\"),\n",
    "        tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=1),\n",
    "    )\n",
    "    features[\"summary_tokens_len\"] = deserialize_composite(\n",
    "        features.get(\"summary_tokens_len\"),\n",
    "        tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=1),\n",
    "    )\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6c4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInputUtils:\n",
    "    def __init__(\n",
    "        self,\n",
    "        bert_preprocessor_path: str = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
    "        encoder_max_seqlen: int = BERT_MAX_SEQLEN,\n",
    "        dynamic_batching: bool = True,\n",
    "        data_max_seq_len: int = None\n",
    "    ):\n",
    "        \"\"\"Initializes a BERT model input preprocessing utility class.\"\"\"\n",
    "        self.bert_preprocessor_path = bert_preprocessor_path\n",
    "        self.preprocessor_module = hub.load(bert_preprocessor_path)\n",
    "        self.encoder_max_seqlen = encoder_max_seqlen\n",
    "        \n",
    "        if not dynamic_batching:\n",
    "            max_seq_len = tf.minimum(data_max_seq_len + 2, encoder_max_seqlen)\n",
    "            self.packer = hub.KerasLayer(\n",
    "                self.preprocessor_module.bert_pack_inputs,\n",
    "                arguments={\"seq_length\": max_seq_len}\n",
    "            )\n",
    "        self.dynamic_batching = tf.constant(dynamic_batching)\n",
    "        \n",
    "    \n",
    "    def pack_inputs(self, batch_tokens: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"Prepares inputs for the BERT encoder\"\"\"\n",
    "        return self.packer([batch_tokens])\n",
    "\n",
    "    def init_packer_and_pack_inputs(\n",
    "        self, batch_tokens: tf.Tensor, batch_token_lens: tf.Tensor\n",
    "    ) -> tf.Tensor:\n",
    "        \"\"\"Prepares inputs for the BERT encoder.\"\"\"\n",
    "        max_token_len = tf.reduce_max(batch_token_lens)\n",
    "        packer = hub.KerasLayer(\n",
    "            self.preprocessor_module.bert_pack_inputs,\n",
    "            arguments={\n",
    "                \"seq_length\": tf.math.minimum(\n",
    "                    max_token_len + 2, self.encoder_max_seqlen\n",
    "                )\n",
    "            },\n",
    "        )\n",
    "        return packer([batch_tokens])\n",
    "\n",
    "    def unravel_ragged_batch(self, ragged_batch, ragged_idx, batch_lens, batch_size):\n",
    "        \"\"\"Flattens out a batch of ragged tensors by one level.\"\"\"\n",
    "        # create indices for each tensor in the batch\n",
    "        # for entries which have multiple ragged tensors, repeat their\n",
    "        # index once for each tensor in the entry\n",
    "        batch_idx = tf.repeat(tf.range(batch_size), batch_lens, axis=0)\n",
    "\n",
    "        # calculate length of the unravelled batch\n",
    "        unravelled_len = tf.reduce_sum(batch_lens)\n",
    "\n",
    "        # create a vector with alternating batch index and ragged tensor index\n",
    "        gather_nd_idx = tf.dynamic_stitch(\n",
    "            indices=[\n",
    "                tf.range(0, (unravelled_len * 2) - 1, 2, dtype=tf.int32),\n",
    "                tf.range(1, unravelled_len * 2, 2, dtype=tf.int32),\n",
    "            ],\n",
    "            data=[batch_idx, ragged_idx.flat_values],\n",
    "        )\n",
    "\n",
    "        # reshape the vector to obtain a unravelled_len x 2 matrix of indices\n",
    "        gather_nd_idx = tf.reshape(gather_nd_idx, shape=[-1, 2])\n",
    "\n",
    "        # obtain the flattened ragged batch using the index matrix\n",
    "        unravelled_tensors = tf.gather_nd(\n",
    "            ragged_batch, indices=gather_nd_idx, batch_dims=0\n",
    "        )\n",
    "\n",
    "        return unravelled_tensors\n",
    "\n",
    "    def get_bert_inputs(self, batch, batch_size):\n",
    "        \"\"\"Generates padded BERT inputs for a given batch of tokenied\n",
    "        text features.\"\"\"\n",
    "        # flatten out the RaggedTensor token batch.\n",
    "        tokens = self.unravel_ragged_batch(\n",
    "            batch.pop(\"summary_tokens\"),\n",
    "            batch.pop(\"summary_sentence_indices\"),\n",
    "            batch[\"summary_num_sentences\"],\n",
    "            batch_size,\n",
    "        )\n",
    "        \n",
    "        # obtain the BERT inputs\n",
    "        bert_inputs = tf.cond(\n",
    "            self.dynamic_batching, \n",
    "            lambda: self.init_packer_and_pack_inputs(\n",
    "                tokens, batch.pop(\"summary_tokens_len\").flat_values\n",
    "            ),\n",
    "            lambda: self.pack_inputs(tokens)\n",
    "        )\n",
    "        return bert_inputs\n",
    "\n",
    "    def preprocess_batch(self, batch: Dict[str, tf.Tensor]):\n",
    "        \"\"\"Applies batch level transformations to the data.\"\"\"\n",
    "        batch_size = tf.shape(batch[\"label\"])[0]\n",
    "\n",
    "        # generate padded BERT inputs for all the text features\n",
    "        batch[\"bert_inputs\"] = self.get_bert_inputs(batch, batch_size)\n",
    "\n",
    "        label = batch.pop(\"label\")\n",
    "        return batch, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20240ca5",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2287f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(split: str, batch_size: int, batch_preprocessor: Callable, shuffle: bool):\n",
    "    \"\"\"Prepares tf.data.Dataset objects from TFRecords.\"\"\"\n",
    "    AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "    ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/{split}-*.tfrecord\")\n",
    "    ds = ds.interleave(\n",
    "        tf.data.TFRecordDataset, cycle_length=AUTO, num_parallel_calls=AUTO\n",
    "    )\n",
    "\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    ds = ds.map(\n",
    "        read_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False\n",
    "    ).cache()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(batch_size * 10)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.map(batch_preprocessor, num_parallel_calls=AUTO)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab367d67",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a1a330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_classifier(\n",
    "    proj_dim: int,\n",
    "    num_labels: int,\n",
    "):\n",
    "    \"\"\"Creates a simple classification model.\"\"\"\n",
    "    input = tf.keras.Input(shape=(BERT_DIM), dtype=tf.int32, name=\"cmlm_embeddings\")\n",
    "\n",
    "    projections = tf.keras.layers.Dense(proj_dim, activation=\"relu\")(input)\n",
    "    probs = tf.keras.layers.Dense(num_labels, activation=\"softmax\")(projections)\n",
    "    return tf.keras.Model(inputs=input, outputs=probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d7cc9",
   "metadata": {},
   "source": [
    "## Training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e39b1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreModelTrainer(tf.keras.Model):\n",
    "    \"\"\"Encapsulates the core model training logic.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "        proj_dim, num_labels, encoder_path, train_encoder=False\n",
    "    ):\n",
    "        super(GenreModelTrainer, self).__init__()\n",
    "        self.predictor = genre_classifier(proj_dim, num_labels)\n",
    "        self.sentence_encoder = hub.KerasLayer(encoder_path)\n",
    "        self.sentence_encoder.trainable = train_encoder\n",
    "\n",
    "    def contiguous_group_average_vectors(self, vectors, groups):\n",
    "        \"\"\"Works iff sum(groups) == len(vectors)\n",
    "        Example:\n",
    "            Inputs: vectors: A dense 2D tensor of shape = (13, 3)\n",
    "                    groups : A dense 1D tensor with values [2, 5, 1, 4, 1]\n",
    "                    indicating that there are 5 groups.\n",
    "            Objective: Compute a 5x3 matrix where the first row\n",
    "                        is the average of the rows 0-1 of `vectors`,\n",
    "                        the second row is the average of rows 2-6 of\n",
    "                        vectors, the third row is the row 7 of vectors,\n",
    "                        the fourth row is the average of rows 8-11 of\n",
    "                        vectors and the fifth and final row is the row\n",
    "                        12 of vectors.\n",
    "            Logic: A selection mask matrix is generated\n",
    "                    mask = [[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "                            [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
    "                            [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    "                            [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
    "                            [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
    "                    This mask is then multiplied with `vectors` to get a\n",
    "                    matrix of shape (5, 3) called `summed_vectors` where\n",
    "                    each row contains the group sums.\n",
    "                    `summed_vectors` is then devided by `groups` to\n",
    "                    obtain the averages.\n",
    "        \"\"\"\n",
    "        groups = tf.expand_dims(tf.cast(groups, dtype=tf.int32), axis=1)\n",
    "        group_cumsum = tf.cumsum(groups)\n",
    "\n",
    "        mask = tf.repeat(\n",
    "            tf.expand_dims(tf.range(tf.shape(vectors)[0]), axis=0),\n",
    "            repeats=tf.shape(groups)[0],\n",
    "            axis=0,\n",
    "        )\n",
    "        mask = tf.cast(mask < group_cumsum, dtype=tf.float32)\n",
    "\n",
    "        def complete_mask(mask):\n",
    "            neg_mask = tf.concat(\n",
    "                (tf.expand_dims(tf.ones_like(mask[0]), axis=0), 1 - mask[:-1]), axis=0\n",
    "            )\n",
    "            return mask * neg_mask\n",
    "\n",
    "        mask = tf.cond(\n",
    "            tf.greater(tf.shape(groups)[0], 1),\n",
    "            true_fn=lambda: complete_mask(mask),\n",
    "            false_fn=lambda: mask,\n",
    "        )\n",
    "\n",
    "        summed_vectors = tf.matmul(mask, vectors)\n",
    "        averaged_vectors = summed_vectors / tf.cast(groups, dtype=tf.float32)\n",
    "\n",
    "        return averaged_vectors\n",
    "\n",
    "    def compute_text_embeddings(self, features):\n",
    "        embeddings = self.sentence_encoder(features[f\"bert_inputs\"])['pooled_output']\n",
    "        embeddings = self.contiguous_group_average_vectors(\n",
    "            embeddings, features[\"summary_num_sentences\"]\n",
    "        )\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        # Unpack the features and the labels.\n",
    "        features, labels = batch\n",
    "\n",
    "        # Compute embeddings for the text features.\n",
    "        embeddings = self.compute_text_embeddings(features)\n",
    "\n",
    "        # Main loop.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.predictor(embeddings, training=True)\n",
    "            loss = self.compiled_loss(labels, predictions)\n",
    "\n",
    "        # Compute gradients and update the parameters.\n",
    "        learnable_params = self.predictor.trainable_variables\n",
    "        gradients = tape.gradient(loss, learnable_params)\n",
    "\n",
    "        # Non-SAM update.\n",
    "        self.optimizer.apply_gradients(zip(gradients, learnable_params))\n",
    "\n",
    "        # Report progress.\n",
    "        self.compiled_metrics.update_state(labels, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        # Unpack the features and the labels.\n",
    "        features, labels = batch\n",
    "\n",
    "        # Get the predictions.\n",
    "        predictions = self.call(features)\n",
    "\n",
    "        # Report progress.\n",
    "        self.compiled_loss(labels, predictions)\n",
    "        self.compiled_metrics.update_state(labels, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def call(self, features):\n",
    "        embeddings = self.compute_text_embeddings(features)\n",
    "        return self.predictor(embeddings, training=False)\n",
    "\n",
    "    def predict_step(self, data):\n",
    "        return self.call(data)\n",
    "\n",
    "    def save_weights(self, filepath, overwrite=True, save_format=None, options=None):\n",
    "        self.predictor.save_weights(\n",
    "            filepath, overwrite=overwrite, save_format=save_format, options=options\n",
    "        )\n",
    "\n",
    "    def load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None):\n",
    "        self.predictor.load_weights(\n",
    "            filepath, by_name=by_name, skip_mismatch=skip_mismatch, options=options\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d9e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_ds: tf.data.Dataset,\n",
    "    valid_ds: tf.data.Dataset,\n",
    "    test_ds: tf.data.Dataset,\n",
    "    num_epochs: int,\n",
    "    run_name: str,\n",
    "    group_name: str,\n",
    "):\n",
    "    tfhub_model_uri = \"https://tfhub.dev/google/universal-sentence-encoder-cmlm/en-base/1\"\n",
    "    # bert_inputs = [\"input_word_ids\", \"input_type_ids\", \"input_mask\"]\n",
    "    proj_dim = 128\n",
    "    num_labels = 27\n",
    "    \n",
    "\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"batching-experiments\",\n",
    "        entity=\"carted\",\n",
    "        name=run_name,\n",
    "        group=group_name,\n",
    "    )\n",
    "\n",
    "    trainer = GenreModelTrainer(proj_dim, num_labels, tfhub_model_uri, False)\n",
    "    trainer.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\",\n",
    "    )\n",
    "    start = time.time()\n",
    "    trainer.fit(\n",
    "        train_ds,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=valid_ds,\n",
    "        callbacks=[wandb.keras.WandbCallback()],\n",
    "    )\n",
    "    end = time.time()\n",
    "    wandb.log({\"model_training_time (seconds)\": end - start})\n",
    "\n",
    "    loss, acc = trainer.evaluate(test_ds)\n",
    "    wandb.log({\"test_loss\": loss})\n",
    "    wandb.log({\"test_acc\": acc})\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab9c7d",
   "metadata": {},
   "source": [
    "## Training with fixed batch length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da308ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-24 14:35:06.990395: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-24 14:35:07.592185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38414 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest token sequence in the training split: 549\n"
     ]
    }
   ],
   "source": [
    "# Find the longest sequence in the training set\n",
    "ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/train-*.tfrecord\")\n",
    "ds = tf.data.TFRecordDataset(ds).map(read_example)\n",
    "max_seq_len = tf.cast(\n",
    "    tf.reduce_max([tf.reduce_max(datum[\"summary_tokens_len\"].flat_values) for datum in ds]), tf.int32\n",
    ")\n",
    "print(f\"Longest token sequence in the training split: {max_seq_len.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41eacf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_utility = ModelInputUtils(dynamic_batching=False, data_max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "350ec5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(split=\"train\", batch_size=BATCH_SIZE, batch_preprocessor=input_utility.preprocess_batch, shuffle=True)\n",
    "valid_ds = get_dataset(split=\"val\", batch_size=BATCH_SIZE, batch_preprocessor=input_utility.preprocess_batch, shuffle=False)\n",
    "test_ds = get_dataset(split=\"test\", batch_size=BATCH_SIZE, batch_preprocessor=input_utility.preprocess_batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fedb0ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcarted\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/opt/conda/envs/var-len-text/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/carted/batching-experiments/runs/kwmbfo3r\" target=\"_blank\">cmlm-fixed-length-run:1</a></strong> to <a href=\"https://wandb.ai/carted/batching-experiments\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-24 14:36:44.821801: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    763/Unknown - 995s 1s/step - loss: 2.9586 - accuracy: 0.2481"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763/763 [==============================] - 1107s 1s/step - loss: 2.9586 - accuracy: 0.2481 - val_loss: 2.5967 - val_accuracy: 0.2459\n",
      "Epoch 2/5\n",
      "  3/763 [..............................] - ETA: 17:21 - loss: 2.5369 - accuracy: 0.2031"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9639/2151660100.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_RUNS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrun_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"cmlm-fixed-length-run:{i + 1}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_9639/1717813350.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_ds, valid_ds, test_ds, num_epochs, run_name, group_name)\u001b[0m\n\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     27\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     trainer.fit(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/var-len-text/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/var-len-text/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/var-len-text/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/var-len-text/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/var-len-text/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/var-len-text/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/var-len-text/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/envs/var-len-text/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/var-len-text/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "group_name = \"split-sentences-fixed-length-batching\"\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    run_name = f\"cmlm-fixed-length-run:{i + 1}\"\n",
    "    train(train_ds, valid_ds, test_ds, NUM_EPOCHS, run_name, group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15867b5f",
   "metadata": {},
   "source": [
    "## Training with variable batch length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ff8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_utility = ModelInputUtils(dynamic_batching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2588588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(split=\"train\", batch_size=BATCH_SIZE, batch_preprocessor=input_utility.preprocess_batch, shuffle=True)\n",
    "valid_ds = get_dataset(split=\"val\", batch_size=BATCH_SIZE, batch_preprocessor=input_utility.preprocess_batch, shuffle=False)\n",
    "test_ds = get_dataset(split=\"test\", batch_size=BATCH_SIZE, batch_preprocessor=input_utility.preprocess_batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e79a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"split-sentences-variable-length-batching\"\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    run_name = f\"cmlm-variable-length-run:{i + 1}\"\n",
    "    train(train_ds, valid_ds, test_ds, NUM_EPOCHS, run_name, group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2369f-34ca-44d6-a210-f9bb919f8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo shutdown now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb101693-383f-4948-b776-aed8423ee842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-var-len-text-py",
   "name": "tf2-gpu.2-6.m84",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m84"
  },
  "kernelspec": {
   "display_name": "Python [conda env:var-len-text]",
   "language": "python",
   "name": "conda-env-var-len-text-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
