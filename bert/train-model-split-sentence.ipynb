{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f943bf42",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as tft\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44377fcf",
   "metadata": {},
   "source": [
    "## Contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS_DIR = \"tfrecords-sentence-splitter\"\n",
    "BERT_MAX_SEQLEN = 512\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126bde2",
   "metadata": {},
   "source": [
    "## TFRecord parsing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a40156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = {\n",
    "    \"summary\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_tokens\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_sentence_indices\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_num_sentences\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "    \"summary_tokens_len\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"label\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_composite(\n",
    "    serialized: bytes, type_spec: tf.RaggedTensorSpec\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Deserializes a serialised ragged tensor.\"\"\"\n",
    "\n",
    "    serialized = tf.io.parse_tensor(serialized, tf.string)\n",
    "    component_specs = tf.nest.flatten(type_spec, expand_composites=True)\n",
    "    components = [\n",
    "        tf.io.parse_tensor(serialized[i], spec.dtype)\n",
    "        for i, spec in enumerate(component_specs)\n",
    "    ]\n",
    "    return tf.nest.pack_sequence_as(type_spec, components, expand_composites=True)\n",
    "\n",
    "\n",
    "def read_example(example):\n",
    "    \"\"\"Parses a single TFRecord file.\"\"\"\n",
    "    features = tf.io.parse_single_example(example, feature_descriptions)\n",
    "    features[\"summary_tokens\"] = deserialize_composite(\n",
    "        features.get(\"summary_tokens\"),\n",
    "        tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=2),\n",
    "    )\n",
    "    features[\"summary_sentence_indices\"] = deserialize_composite(\n",
    "        features.get(\"summary_sentence_indices\"),\n",
    "        tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=1),\n",
    "    )\n",
    "    features[\"summary_tokens_len\"] = deserialize_composite(\n",
    "        features.get(\"summary_tokens_len\"),\n",
    "        tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=1),\n",
    "    )\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInputUtils:\n",
    "    def __init__(\n",
    "        self,\n",
    "        bert_preprocessor_path: str = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
    "        encoder_max_seqlen: int = BERT_MAX_SEQLEN,\n",
    "    ):\n",
    "        \"\"\"Initializes a BERT model input preprocessing utility class.\"\"\"\n",
    "        self.bert_preprocessor_path = bert_preprocessor_path\n",
    "        self.preprocessor_module = hub.load(bert_preprocessor_path)\n",
    "        self.encoder_max_seqlen = encoder_max_seqlen\n",
    "\n",
    "    def init_packer_and_pack_inputs(\n",
    "        self, batch_tokens: tf.Tensor, batch_token_lens: tf.Tensor\n",
    "    ) -> tf.Tensor:\n",
    "        \"\"\"Prepares inputs for the BERT encoder.\"\"\"\n",
    "        max_token_len = tf.reduce_max(batch_token_lens)\n",
    "        packer = hub.KerasLayer(\n",
    "            self.preprocessor_module.bert_pack_inputs,\n",
    "            arguments={\n",
    "                \"seq_length\": tf.math.minimum(\n",
    "                    max_token_len + 2, self.encoder_max_seqlen\n",
    "                )\n",
    "            },\n",
    "        )\n",
    "        return packer([batch_tokens])\n",
    "\n",
    "    def unravel_ragged_batch(self, ragged_batch, ragged_idx, batch_lens, batch_size):\n",
    "        \"\"\"Flattens out a batch of ragged tensors by one level.\"\"\"\n",
    "        # create indices for each tensor in the batch\n",
    "        # for entries which have multiple ragged tensors, repeat their\n",
    "        # index once for each tensor in the entry\n",
    "        batch_idx = tf.repeat(tf.range(batch_size), batch_lens, axis=0)\n",
    "\n",
    "        # calculate length of the unravelled batch\n",
    "        unravelled_len = tf.reduce_sum(batch_lens)\n",
    "\n",
    "        # create a vector with alternating batch index and ragged tensor index\n",
    "        gather_nd_idx = tf.dynamic_stitch(\n",
    "            indices=[\n",
    "                tf.range(0, (unravelled_len * 2) - 1, 2, dtype=tf.int32),\n",
    "                tf.range(1, unravelled_len * 2, 2, dtype=tf.int32),\n",
    "            ],\n",
    "            data=[batch_idx, ragged_idx.flat_values],\n",
    "        )\n",
    "\n",
    "        # reshape the vector to obtain a unravelled_len x 2 matrix of indices\n",
    "        gather_nd_idx = tf.reshape(gather_nd_idx, shape=[-1, 2])\n",
    "\n",
    "        # obtain the flattened ragged batch using the index matrix\n",
    "        unravelled_tensors = tf.gather_nd(\n",
    "            ragged_batch, indices=gather_nd_idx, batch_dims=0\n",
    "        )\n",
    "\n",
    "        return unravelled_tensors\n",
    "\n",
    "    def get_bert_inputs(self, batch, batch_size):\n",
    "        \"\"\"Generates padded BERT inputs for a given batch of tokenied\n",
    "        text features.\"\"\"\n",
    "        # flatten out the RaggedTensor token batch.\n",
    "        tokens = self.unravel_ragged_batch(\n",
    "            batch.pop(\"summary_tokens\"),\n",
    "            batch.pop(\"summary_sentence_indices\"),\n",
    "            batch[\"summary_num_sentences\"],\n",
    "            batch_size,\n",
    "        )\n",
    "        # obtain the BERT inputs\n",
    "        batch[\"summary_tokens\"] = tokens\n",
    "        bert_inputs = self.init_packer_and_pack_inputs(\n",
    "            tokens, batch.pop(\"summary_tokens_len\").flat_values\n",
    "        )\n",
    "        return bert_inputs\n",
    "\n",
    "    def preprocess_batch(self, batch: Dict[str, tf.Tensor]):\n",
    "        \"\"\"Applies batch level transformations to the data.\"\"\"\n",
    "        batch_size = tf.shape(batch[\"label\"])[0]\n",
    "\n",
    "        # generate padded BERT inputs for all the text features\n",
    "        batch[\"bert_inputs\"] = self.get_bert_inputs(batch, batch_size)\n",
    "\n",
    "        label = batch.pop(\"label\")\n",
    "        return batch, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20240ca5",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f378ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_utils = ModelInputUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2287f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(split, batch_size, shuffle):\n",
    "    \"\"\"Prepares tf.data.Dataset objects from TFRecords.\"\"\"\n",
    "    ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/{split}-*.tfrecord\")\n",
    "    ds = ds.interleave(\n",
    "        tf.data.TFRecordDataset, cycle_length=3, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    ds = ds.map(\n",
    "        read_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False\n",
    "    ).cache()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(batch_size * 10)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.map(input_utils.preprocess_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ec5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(\"train\", BATCH_SIZE, True)\n",
    "valid_ds = get_dataset(\"val\", BATCH_SIZE, False)\n",
    "test_ds = get_dataset(\"test\", BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_features, batch_labels in train_ds.take(1):\n",
    "    print(batch_features.keys())\n",
    "    print(batch_labels.shape)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
