{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f943bf42",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as tft\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44377fcf",
   "metadata": {},
   "source": [
    "## Contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS_DIR = \"gs://variable-length-sequences-tf/tfrecords\"\n",
    "BERT_MAX_SEQLEN = 512\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126bde2",
   "metadata": {},
   "source": [
    "## TFRecord parsing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a40156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = {\n",
    "    \"summary\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_tokens\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_tokens_len\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "    \"label\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_composite(serialized, type_spec):\n",
    "    \"\"\"Parses a serialized Ragged features and retains the original structure.\"\"\"\n",
    "    serialized = tf.io.parse_tensor(serialized, tf.string)\n",
    "    component_specs = tf.nest.flatten(type_spec, expand_composites=True)\n",
    "    components = [\n",
    "        tf.io.parse_tensor(serialized[i], spec.dtype)\n",
    "        for i, spec in enumerate(component_specs)\n",
    "    ]\n",
    "    return tf.nest.pack_sequence_as(type_spec, components, expand_composites=True)\n",
    "\n",
    "\n",
    "def read_example(example):\n",
    "    \"\"\"Parses a single TFRecord file.\"\"\"\n",
    "    features = tf.io.parse_single_example(example, feature_descriptions)\n",
    "    features[\"summary_tokens\"] = deserialize_composite(\n",
    "        features.get(\"summary_tokens\"),\n",
    "        tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=2),\n",
    "    )\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_text_preprocessor(preprocessor_path: str) -> Callable:\n",
    "    \"\"\" Decorator to set the desired preprocessor for a\n",
    "        function from a TensorFlow Hub URL.\n",
    "        \n",
    "    Arguments:\n",
    "        preprocessor_path {str} -- URL of the TF-Hub preprocessor.\n",
    "    \n",
    "    Returns:\n",
    "        Callable -- A function with the `preprocessor` attribute set.\n",
    "    \"\"\"\n",
    "    def decoration(func: Callable):\n",
    "        # Loading the preprocessor from TF-Hub\n",
    "        preprocessor = hub.load(preprocessor_path)\n",
    "        \n",
    "        # Setting an attribute called `preprocessor` to\n",
    "        # the passed function\n",
    "        func.preprocessor = preprocessor\n",
    "        return func\n",
    "    return decoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4379e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@set_text_preprocessor(\n",
    "    preprocessor_path=\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    ")\n",
    "def preprocess_batch(batch):\n",
    "    \"\"\"Batch processing utility.\"\"\"\n",
    "    text_tokens_max_len = tf.cast(\n",
    "        tf.math.reduce_max(batch[\"summary_tokens_len\"]), dtype=tf.int32,\n",
    "    )\n",
    "\n",
    "    # Generating the inputs for the BERT model.\n",
    "    bert_input_packer = hub.KerasLayer(\n",
    "        preprocess_batch.preprocessor.bert_pack_inputs,\n",
    "        arguments={\"seq_length\": tf.minimum(text_tokens_max_len + 2, BERT_MAX_SEQLEN)},\n",
    "    )\n",
    "    bert_packed_text = bert_input_packer(\n",
    "        [tf.squeeze(batch.pop(\"summary_tokens\"), axis=1)]\n",
    "    )\n",
    "\n",
    "    labels = batch.pop(\"label\")\n",
    "    return bert_packed_text, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20240ca5",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2287f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(split, batch_size, shuffle):\n",
    "    \"\"\"Prepares tf.data.Dataset objects from TFRecords.\"\"\"\n",
    "    ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/{split}-*.tfrecord\")\n",
    "    ds = ds.interleave(\n",
    "        tf.data.TFRecordDataset, cycle_length=3, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    ds = ds.map(\n",
    "        read_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False\n",
    "    ).cache()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(batch_size * 10)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.map(preprocess_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ec5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(\"train\", BATCH_SIZE, True)\n",
    "valid_ds = get_dataset(\"val\", BATCH_SIZE, False)\n",
    "test_ds = get_dataset(\"test\", BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, labels in train_ds.take(1):\n",
    "    print(features.keys())\n",
    "    print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59501ed9",
   "metadata": {},
   "source": [
    "## Analyzing the maximum sequence lengths over training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d95a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/train-*.tfrecord\")\n",
    "analysis_ds = analysis_ds.interleave(\n",
    "    tf.data.TFRecordDataset, cycle_length=3, num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "analysis_ds = analysis_ds.map(\n",
    "    read_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False\n",
    ")\n",
    "analysis_ds = analysis_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seqlens = []\n",
    "batches = 0\n",
    "\n",
    "\n",
    "for batch in analysis_ds:\n",
    "    max_seqlens.append(\n",
    "        int(tf.cast(tf.math.reduce_max(batch[\"summary_tokens_len\"]), dtype=tf.int32,))\n",
    "    )\n",
    "    batches += 1\n",
    "\n",
    "plt.plot(np.arange(batches), max_seqlens)\n",
    "plt.xlabel(\"Batch #\", fontsize=14)\n",
    "plt.ylabel(\"Maximum sequence lengths\", fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
