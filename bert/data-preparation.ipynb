{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ce6d15",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* https://www.kaggle.com/rohitganji13/film-genre-classification-using-nlp\n",
    "* Internal (Carted) TFRecord utilities contributed by [Nilabhra Roy Chowdhury](https://www.linkedin.com/in/nilabhraroychowdhury/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee8005",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced81606",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-splitter tensorflow-hub tensorflow_text -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4005bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1CvkRnGC8b_-n1NcbwcwxcIq7SusmDMb5\n",
      "To: /Users/nilabhraroychowdhury/handling-variable-length-text-tf/bert/train_data.txt\n",
      "100%|██████████████████████████████████████| 35.4M/35.4M [00:04<00:00, 8.72MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1h1evGF5NVi2p8RoWxl8xhpOod0ZN_-ky\n",
      "To: /Users/nilabhraroychowdhury/handling-variable-length-text-tf/bert/test_data_solution.txt\n",
      "100%|██████████████████████████████████████| 35.4M/35.4M [00:03<00:00, 9.78MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1CvkRnGC8b_-n1NcbwcwxcIq7SusmDMb5 -O train_data.txt\n",
    "!gdown --id 1h1evGF5NVi2p8RoWxl8xhpOod0ZN_-ky -O test_data_solution.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65fc8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Callable, Tuple, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe67b35a",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Data comes from here: https://www.kaggle.com/hijest/genre-classification-dataset-imdb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39fc6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"train_data.txt\",\n",
    "    engine=\"python\",\n",
    "    sep=\" ::: \",\n",
    "    names=[\"id\", \"movie\", \"genre\", \"summary\"],\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    \"test_data_solution.txt\",\n",
    "    engine=\"python\",\n",
    "    sep=\" ::: \",\n",
    "    names=[\"id\", \"movie\", \"genre\", \"summary\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c1b5c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oscar et la dame rose (2009)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cupid (1997)</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Young, Wild and Wonderful (1980)</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Secret Sin (1915)</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Unrecovered (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>The film's title refers not only to the un-rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                             movie     genre  \\\n",
       "0   1      Oscar et la dame rose (2009)     drama   \n",
       "1   2                      Cupid (1997)  thriller   \n",
       "2   3  Young, Wild and Wonderful (1980)     adult   \n",
       "3   4             The Secret Sin (1915)     drama   \n",
       "4   5            The Unrecovered (2007)     drama   \n",
       "\n",
       "                                             summary  \n",
       "0  Listening in to a conversation between his doc...  \n",
       "1  A brother and sister with a past incestuous re...  \n",
       "2  As the bus empties the students for their fiel...  \n",
       "3  To help their unemployed father make ends meet...  \n",
       "4  The film's title refers not only to the un-rec...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing training data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2754413",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e8d0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 48792.\n",
      "Number of validation samples: 5422.\n",
      "Number of test examples: 54200.\n"
     ]
    }
   ],
   "source": [
    "# Split the data using train_test_split from sklearn\n",
    "train_shuffled = train_df.sample(frac=1)\n",
    "train_df_new, val_df = train_test_split(train_shuffled, test_size=0.1)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_df_new)}.\")\n",
    "print(f\"Number of validation samples: {len(val_df)}.\")\n",
    "print(f\"Number of test examples: {len(test_df)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149c90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_df_new[\"genre\"].values) \n",
    "\n",
    "train_df_new[\"genre\"] = le.transform(train_df_new[\"genre\"].values)\n",
    "val_df[\"genre\"] = le.transform(val_df[\"genre\"].values)\n",
    "test_df[\"genre\"] = le.transform(test_df[\"genre\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2996d9",
   "metadata": {},
   "source": [
    "## Data preprocessing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e44536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_tokenizer(preprocessor_path: str) -> Callable:\n",
    "    \"\"\" Decorator to set the desired tokenizer for a tokenizing\n",
    "        function from a TensorFlow Hub URL.\n",
    "        \n",
    "    Arguments:\n",
    "        preprocessor_path {str} -- URL of the TF-Hub preprocessor.\n",
    "    \n",
    "    Returns:\n",
    "        Callable -- A function with the `tokenizer` attribute set.\n",
    "    \"\"\"\n",
    "\n",
    "    def decoration(func: Callable):\n",
    "        # Loading the preprocessor from TF-Hub\n",
    "        preprocessor = hub.load(preprocessor_path)\n",
    "\n",
    "        # Setting an attribute called `tokenizer` to\n",
    "        # the passed function\n",
    "        func.tokenizer = preprocessor.tokenize\n",
    "        return func\n",
    "\n",
    "    return decoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e8a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(bytes_input: bytes) -> tf.train.Feature:\n",
    "    \"\"\"Encodes given data as a byte feature.\"\"\"\n",
    "    bytes_list = tf.train.BytesList(value=[bytes_input])\n",
    "    return tf.train.Feature(bytes_list=bytes_list)\n",
    "\n",
    "\n",
    "def _ints_feature(int_input: int) -> tf.train.Feature:\n",
    "    \"\"\"Encoded given data as an integer feature.\"\"\"\n",
    "    int64_list = tf.train.Int64List(value=int_input)\n",
    "    return tf.train.Feature(int64_list=int64_list)\n",
    "\n",
    "\n",
    "def _ragged_feature(ragged_input: tf.RaggedTensor, name: str) -> Dict[str, tf.train.Feature]:\n",
    "    \"\"\"Returns a dictionary to represent a single ragged tensor as int64 features.\"\"\"\n",
    "    ret = {\n",
    "        f\"{name}_values\": _ints_feature(ragged_input.flat_values)\n",
    "    }\n",
    "    for i, d in enumerate(ragged_input.nested_row_splits):\n",
    "        ret[f\"{name}_splits_{i}\"] = _ints_feature(d)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebdd96c",
   "metadata": {},
   "source": [
    "To know more about these utilities refer to the official guide [here](https://www.tensorflow.org/tutorials/load_data/tfrecord)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da6d30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 13:44:23.438475: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "@set_tokenizer(\n",
    "    preprocessor_path=\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    ")\n",
    "def _tokenize_text(text: str) -> Tuple[tf.RaggedTensor, int]:\n",
    "    \"\"\"Tokenizes text and returns text token and their length.\"\"\"\n",
    "    toks = _tokenize_text.tokenizer(tf.constant([text]))\n",
    "    num_tokens = toks.flat_values.shape[-1]\n",
    "    return toks, num_tokens\n",
    "\n",
    "\n",
    "# def serialize_composite(rt):\n",
    "#     \"\"\"Serializes as a Ragged feature.\"\"\"\n",
    "#     components = tf.nest.flatten(rt, expand_composites=True)\n",
    "#     return tf.io.serialize_tensor(\n",
    "#         tf.stack([tf.io.serialize_tensor(t) for t in components])\n",
    "#     ).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61ac19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = hub.load(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "tokenizer = preprocessor.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae71fdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[[2044], [13012, 4095, 2532], [19941], [2014], [12074], [1010], [2852], [1012], [27133, 21426], [1038, 8167, 3654, 3567], [1010], [2016], [4858], [2041], [2008], [2002], [2109], [2000], [2293], [2003, 23935], [5960, 13241], [1010], [1996], [2069], [2684], [1997], [1037], [4800], [1011], [19965], [1012], [2016], [2036], [4858], [2041], [2008], [2014], [3510], [2000], [27133, 21426], [4504], [1999], [1037], [2350], [12603], [2005], [2003, 23935], [1010], [2040], [2018], [2000], [2022], [12148, 3550], [2005], [8811], [1012], [2085], [2003, 23935], [2038], [6757], [1010], [1998], [2619], [2003], [2667], [2000], [3102], [13012, 4095, 2532], [1010], [1998], [1996], [3291], [2003], [2008], [2053], [2028], [2003], [5627], [2000], [2903], [2014], [1012]]]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(len(train_df_new))\n",
    "sample_text = train_df_new[\"summary\"][idx]\n",
    "tokens = tokenizer([sample_text])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "887737e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alan Bennett and director Nicholas Hytner discuss and dissect the process they went through to produce the final version of The Habit of Art, the critically acclaimed play in which a group of actors rehearse a play about W.H. Auden and Benjamin Britten.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40d6c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize_composite(tokenizer([sample_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fad8daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# components = tokenizer([sample_text])\n",
    "# tf.io.serialize_tensor(components).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3c3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(row):\n",
    "    \"\"\"Creates one TFRecord example.\"\"\"\n",
    "    summary = row[\"summary\"]\n",
    "    label = row[\"genre\"]\n",
    "\n",
    "    description = bytes(summary, encoding=\"utf-8\")\n",
    "    description_tokens, description_len = _tokenize_text(summary)\n",
    "\n",
    "    feature = {\n",
    "        \"summary\": _bytes_feature(description),\n",
    "        \"summary_tokens_len\": _ints_feature([description_len]),\n",
    "        \"label\": _ints_feature([label]),\n",
    "    }\n",
    "    feature.update(_ragged_feature(description_tokens, \"summary_tokens\"))\n",
    "    feature = tf.train.Features(feature=feature)\n",
    "    example = tf.train.Example(features=feature)\n",
    "    return example\n",
    "\n",
    "\n",
    "def write_tfrecords(file_name, data):\n",
    "    \"\"\"Serializes the data as string.\"\"\"\n",
    "    with tf.io.TFRecordWriter(file_name) as writer:\n",
    "        for i, row in data.iterrows():\n",
    "            example = create_example(row)\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a0aed",
   "metadata": {},
   "source": [
    "## Write to TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "347762b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS_DIR = \"tfrecords\"\n",
    "tf.io.gfile.makedirs(TFRECORDS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cf499c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(data, chunk_size, files_prefix):\n",
    "    \"\"\"Serializes data as TFRecord shards.\"\"\"\n",
    "    example_counter = 0\n",
    "    chunk_count = 1\n",
    "    for i in tqdm.tqdm(range(0, data.shape[0], chunk_size)):\n",
    "        chunk = data.iloc[i : i + chunk_size, :]\n",
    "        file_name = f\"{TFRECORDS_DIR}/{files_prefix}-{chunk_count:02d}.tfrecord\"\n",
    "        write_tfrecords(file_name, chunk)\n",
    "        example_counter += chunk.shape[0]\n",
    "        chunk_count += 1\n",
    "    return example_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4250f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17ec541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [22:57<00:00,  2.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48792"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_example_count = write_data(train_df_new, CHUNK_SIZE, \"train\")\n",
    "train_example_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4192fc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [1:34:07<00:00, 102.69s/it]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5422"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_example_count = write_data(val_df, CHUNK_SIZE, \"val\")\n",
    "val_example_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6724a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 542/542 [15:32:20<00:00, 103.21s/it]     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example_count = write_data(test_df, CHUNK_SIZE, \"test\")\n",
    "test_example_count"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
