{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f943bf42",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9014279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Dict\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44377fcf",
   "metadata": {},
   "source": [
    "## Contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d42dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFRECORDS_DIR = \"gs://variable-length-sequences-tf/tfrecords\"\n",
    "TFRECORDS_DIR = \"tfrecords\"\n",
    "BERT_MAX_SEQLEN = 512\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126bde2",
   "metadata": {},
   "source": [
    "## TFRecord parsing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a40156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = {\n",
    "    \"summary\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_tokens\": tf.io.RaggedFeature(\n",
    "        value_key=\"summary_tokens_values\",\n",
    "        dtype=tf.int64,\n",
    "        partitions=[\n",
    "            tf.io.RaggedFeature.RowSplits(\n",
    "                \"summary_tokens_splits_0\"\n",
    "            ),\n",
    "            tf.io.RaggedFeature.RowSplits(\n",
    "                \"summary_tokens_splits_1\"\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    \"summary_tokens_len\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "    \"label\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a5de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def deserialize_composite(serialized, type_spec):\n",
    "#     \"\"\"Parses a serialized Ragged features and retains the original structure.\"\"\"\n",
    "#     serialized = tf.io.parse_tensor(serialized, tf.string)\n",
    "#     component_specs = tf.nest.flatten(type_spec, expand_composites=True)\n",
    "#     components = [\n",
    "#         tf.io.parse_tensor(serialized[i], spec.dtype)\n",
    "#         for i, spec in enumerate(component_specs)\n",
    "#     ]\n",
    "#     return tf.nest.pack_sequence_as(type_spec, components, expand_composites=True)\n",
    "\n",
    "def read_example(example):\n",
    "    \"\"\"Parses a single TFRecord file.\"\"\"\n",
    "    features = tf.io.parse_single_example(example, feature_descriptions)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d2384",
   "metadata": {},
   "source": [
    "## Preprocessing function for fixed length batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a780d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'\\n\\xb2\\x08\\n\\xc5\\x04\\n\\x07summary\\x12\\xb9\\x04\\n\\xb6\\x04\\n\\xb3\\x04This NZBC religious programme goes where TV cameras had never gone before: behind the walls of the Carmelite monastery in Christchurch. There, it finds a community of 16 Catholic nuns, members of a 400-year-old order, who have shut themselves off from the outside world to lead lives devoted to prayer, contemplation and simple manual work. Despite their seclusion, the sisters are unphased by the intrusion and happy to discuss their lives and their beliefs; while the simplicity and ceremony of their world provides fertile ground for the monochrome camerawork.\\n!\\n\\x17summary_tokens_splits_0\\x12\\x06\\x1a\\x04\\n\\x02\\x00g\\n\\x8d\\x02\\n\\x15summary_tokens_values\\x12\\xf3\\x01\\x1a\\xf0\\x01\\n\\xed\\x01\\xe7\\x0f\\xa8\\x9c\\x01\\xdaL\\xd4\\x1a\\x8a%\\xb0\\x1c\\x99\\x10\\x86\\x15\\xb5C\\xe2\\x0f\\x94\\x11\\xdc\\x16\\x9d\\x10\\x80\\x08\\xc1\\x12\\xcc\\x0f\\xe1\\x1c\\xcd\\x0f\\xcc\\x0f\\xf3\\x97\\x01\\xfd \\x882\\xcf\\x0f\\x88|\\xf4\\x07\\xfd\\x0f\\xf2\\x07\\xd9\\x0f\\xfa%\\x8d\\x08\\x93\\x13\\xcd\\x0f\\xd1\\x12\\xa2\\x19\\xf0\\x82\\x01\\xf2\\x07\\xc4\\x12\\xcd\\x0f\\x8d\\x08\\xb6!\\xf3\\x07\\xaf\\x10\\xf3\\x07\\xa6\\x11\\xa8\\x12\\xf2\\x07\\xf8\\x0f\\xef\\x0f\\x84\\x1e\\x89\\x19\\xcd\\x10\\xdd\\x0f\\xcc\\x0f\\xd8\\x14\\xa8\\x10\\xd0\\x0f\\xa7\\x14\\xc4\\x19\\xfe9\\xd0\\x0f\\xab7\\xf2\\x07\\xbaJ\\xe4\\x90\\x01\\xb7\\xc1\\x01\\xaa\\x1a\\xce\\x0f\\x8a\\x1d\\x8a2\\xe3\\x10\\xf4\\x07\\xbe\\x15\\xf5\\x0f\\xc3T\\xb5\\xbc\\x01\\xf2\\x07\\xcc\\x0f\\xd8(\\xe8\\x0f\\x9f&\\x82\\xab\\x01\\x8c6\\xdb\\x0f\\xcc\\x0f\\xea\\xbf\\x01\\xce\\x0f\\xcf\\x1a\\xd0\\x0f\\xc05\\xf5\\x0f\\xc4\\x19\\xce\\x0f\\xf5\\x0f\\xc5F\\x81\\x08\\xb0\\x10\\xcc\\x0f\\xaf\\x8b\\x01\\xce\\x0f\\xef\\'\\xcd\\x0f\\xf5\\x0f\\xa8\\x10\\xb8\\x1c\\xe2t\\xa6\\x14\\xd5\\x0f\\xcc\\x0f\\x9f\\x93\\x01\\x8e\\x9f\\x01\\xd6&\\xb60\\xf4\\x07\\n\\x87\\x01\\n\\x17summary_tokens_splits_1\\x12l\\x1aj\\nh\\x00\\x01\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\x0c\\r\\x0e\\x0f\\x10\\x11\\x12\\x13\\x15\\x16\\x17\\x18\\x19\\x1a\\x1b\\x1c\\x1d\\x1e\\x1f !\"#$%&\\'()*+,-./0123456789:;<=>BCDEFGHIKLMNORSTUVWXYZ[\\\\]^_`abcdefghijklnpq\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x1b\\n\\x12summary_tokens_len\\x12\\x05\\x1a\\x03\\n\\x01q', shape=(), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 03:32:43.617302: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Find the longest sequence in the training set\n",
    "ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/train-*.tfrecord\")\n",
    "ds = tf.data.TFRecordDataset(ds)\n",
    "\n",
    "for d in ds:\n",
    "    print(d)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "474df024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest token sequence in the training split: 2947\n"
     ]
    }
   ],
   "source": [
    "# Find the longest sequence in the training set\n",
    "ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/train-*.tfrecord\")\n",
    "ds = tf.data.TFRecordDataset(ds).map(\n",
    "    lambda example: tf.io.parse_single_example(example, feature_descriptions)\n",
    ")\n",
    "max_seq_len = tf.cast(\n",
    "    tf.reduce_max([datum[\"summary_tokens_len\"] for datum in ds]), tf.int32\n",
    ")\n",
    "print(f\"Longest token sequence in the training split: {max_seq_len.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f067d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = hub.load(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "fixed_len_bert_packer = hub.KerasLayer(\n",
    "    preprocessor.bert_pack_inputs,\n",
    "    arguments={\"seq_length\": tf.minimum(max_seq_len + 2, BERT_MAX_SEQLEN)},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37448903",
   "metadata": {},
   "source": [
    "#### Note: We add 2 to the maximum length to account for the CLS and SEP tokens that would be added later by the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6be99af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fixed_batch(batch):\n",
    "    \"\"\"Batch processing utility.\"\"\"\n",
    "\n",
    "    # Generating the inputs for the BERT model.\n",
    "    bert_packed_text = fixed_len_bert_packer(\n",
    "        [tf.squeeze(batch.pop(\"summary_tokens\"), axis=1)]\n",
    "    )\n",
    "\n",
    "    labels = batch.pop(\"label\")\n",
    "    return bert_packed_text, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fa686e",
   "metadata": {},
   "source": [
    "## Preprocessing function for variable length batching using the BERT packer from TF Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74f3ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_text_preprocessor(preprocessor_path: str) -> Callable:\n",
    "    \"\"\"Decorator to set the desired preprocessor for a\n",
    "        function from a TensorFlow Hub URL.\n",
    "\n",
    "    Arguments:\n",
    "        preprocessor_path {str} -- URL of the TF-Hub preprocessor.\n",
    "\n",
    "    Returns:\n",
    "        Callable -- A function with the `preprocessor` attribute set.\n",
    "    \"\"\"\n",
    "\n",
    "    def decoration(func: Callable):\n",
    "        # Loading the preprocessor from TF-Hub\n",
    "        preprocessor = hub.load(preprocessor_path)\n",
    "\n",
    "        # Setting an attribute called `preprocessor` to\n",
    "        # the passed function\n",
    "        func.preprocessor = preprocessor\n",
    "        return func\n",
    "\n",
    "    return decoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a4379e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@set_text_preprocessor(\n",
    "    preprocessor_path=\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    ")\n",
    "def preprocess_variable_batch_tfh(batch):\n",
    "    \"\"\"Batch processing utility.\"\"\"\n",
    "    text_tokens_max_len = tf.cast(\n",
    "        tf.math.reduce_max(batch[\"summary_tokens_len\"]),\n",
    "        dtype=tf.int32,\n",
    "    )\n",
    "\n",
    "    # Generating the inputs for the BERT model.\n",
    "    bert_input_packer = hub.KerasLayer(\n",
    "        preprocess_variable_batch_tfh.preprocessor.bert_pack_inputs,\n",
    "        arguments={\"seq_length\": tf.minimum(text_tokens_max_len + 2, BERT_MAX_SEQLEN)},\n",
    "    )\n",
    "    bert_packed_text = bert_input_packer(\n",
    "        [tf.squeeze(batch.pop(\"summary_tokens\"), axis=1)]\n",
    "    )\n",
    "\n",
    "    labels = batch.pop(\"label\")\n",
    "    return bert_packed_text, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb54e58",
   "metadata": {},
   "source": [
    "## Preprocessing function for variable length batching using a custom written BERT packer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b71aa7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_bert_inputs(\n",
    "    batch_tokens: tf.RaggedTensor,\n",
    "    batch_lens: tf.Tensor,\n",
    "    max_len: int = tf.constant(512),\n",
    ") -> Dict[str, tf.Tensor]:\n",
    "    \"\"\"Pack the tokens w.r.t BERT inputs.\"\"\"\n",
    "\n",
    "    # Remove the last ragged dimension\n",
    "    batch_tokens = tf.RaggedTensor.from_row_lengths(\n",
    "        batch_tokens.flat_values, batch_lens\n",
    "    )\n",
    "\n",
    "    # Calcuate batch size.\n",
    "    batch_size = tf.shape(batch_lens)[0]\n",
    "\n",
    "    # Define special token values (very specific to BERT).\n",
    "    CLS = 101\n",
    "    SEP = 102\n",
    "    PAD = 0\n",
    "\n",
    "    # Prepare the special tokens for concatenation.\n",
    "    batch_cls = tf.repeat(tf.constant([[CLS]]), batch_size, axis=0)\n",
    "    batch_cls = tf.RaggedTensor.from_tensor(batch_cls).with_row_splits_dtype(\n",
    "        batch_tokens.row_splits.dtype\n",
    "    )\n",
    "    batch_sep = tf.repeat(tf.constant([[SEP]]), batch_size, axis=0)\n",
    "    batch_sep = tf.RaggedTensor.from_tensor(batch_sep).with_row_splits_dtype(\n",
    "        batch_tokens.row_splits.dtype\n",
    "    )\n",
    "\n",
    "    # Truncate the sequences that are shorter than max_len.\n",
    "    max_batch_len = tf.minimum(tf.reduce_max(batch_lens) + 2, max_len)\n",
    "    truncated_tokens = batch_tokens[:, : max_batch_len - 2]\n",
    "\n",
    "    # Sandwich the truncated tokens in between the special tokens.\n",
    "    prepared_tokens = tf.concat([batch_cls, truncated_tokens, batch_sep], axis=1)\n",
    "\n",
    "    # Convert the tokens to a regular int32 tensor and pad the\n",
    "    # shorter sequences with PAD.\n",
    "    padded_tokens = prepared_tokens.to_tensor(PAD)\n",
    "\n",
    "    # Create the segment id tensor.\n",
    "    segment_ids = tf.zeros_like(padded_tokens)\n",
    "\n",
    "    # Create the input mask\n",
    "    mask = tf.sequence_mask(batch_lens + 2, max_batch_len, dtype=tf.int32)\n",
    "\n",
    "    ret = {\n",
    "        \"input_word_ids\": padded_tokens,\n",
    "        \"input_type_ids\": segment_ids,\n",
    "        \"input_mask\": mask,\n",
    "    }\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c39c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_variable_batch_cust(batch):\n",
    "    \"\"\"Batch processing utility.\"\"\"\n",
    "    text_token_lens = tf.cast(batch[\"summary_tokens_len\"], dtype=tf.int32)\n",
    "\n",
    "    # Generating the inputs for the BERT model.\n",
    "    bert_packed_text = prepare_bert_inputs(\n",
    "        tf.squeeze(batch[\"summary_tokens\"], axis=1), tf.reshape(text_token_lens, (-1,))\n",
    "    )\n",
    "    labels = batch.pop(\"label\")\n",
    "    return bert_packed_text, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20240ca5",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2287f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(\n",
    "    split: str, batch_size: int, batch_preprocessor: Callable, shuffle: bool\n",
    "):\n",
    "    \"\"\"Prepares tf.data.Dataset objects from TFRecords.\"\"\"\n",
    "    AUTO = tf.data.AUTOTUNE\n",
    "    ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/{split}-*.tfrecord\")\n",
    "    ds = (\n",
    "        ds.interleave(\n",
    "            tf.data.TFRecordDataset,\n",
    "            cycle_length=AUTO,\n",
    "            num_parallel_calls=AUTO,\n",
    "        )\n",
    "        .map(read_example, num_parallel_calls=AUTO, deterministic=False)\n",
    "        .cache()\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(batch_size * 10)\n",
    "    ds = (\n",
    "        ds.batch(batch_size)\n",
    "        .map(batch_preprocessor, num_parallel_calls=AUTO)\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2aca18",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "816f420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_classifier(\n",
    "    encoder_path: str,\n",
    "    input_features: List[str],\n",
    "    train_encoder: bool,\n",
    "    proj_dim: int,\n",
    "    num_labels: int,\n",
    "):\n",
    "    \"\"\"Creates a simple classification model.\"\"\"\n",
    "    text_encoder = hub.KerasLayer(encoder_path)\n",
    "    text_encoder.trainable = train_encoder\n",
    "\n",
    "    inputs = {\n",
    "        feature_name: tf.keras.Input(shape=(None,), dtype=tf.int32, name=feature_name)\n",
    "        for feature_name in input_features\n",
    "    }\n",
    "\n",
    "    text_encodings = text_encoder(inputs)\n",
    "    projections = tf.keras.layers.Dense(proj_dim, activation=\"relu\")(\n",
    "        text_encodings[\"pooled_output\"]\n",
    "    )\n",
    "    probs = tf.keras.layers.Dense(num_labels, activation=\"softmax\")(projections)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc4f9d1",
   "metadata": {},
   "source": [
    "## Training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5831bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_ds: tf.data.Dataset,\n",
    "    valid_ds: tf.data.Dataset,\n",
    "    test_ds: tf.data.Dataset,\n",
    "    num_epochs: int,\n",
    "    run_name: str,\n",
    "    group_name: str,\n",
    "):\n",
    "    tfhub_model_uri = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "    bert_inputs = [\"input_word_ids\", \"input_type_ids\", \"input_mask\"]\n",
    "    proj_dim = 128\n",
    "    num_labels = 27\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"batching-experiments\",\n",
    "        entity=\"carted\",\n",
    "        name=run_name,\n",
    "        group=group_name,\n",
    "    )\n",
    "\n",
    "    model = genre_classifier(tfhub_model_uri, bert_inputs, False, proj_dim, num_labels)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\"\n",
    "    )\n",
    "    start = time.time()\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=valid_ds,\n",
    "        callbacks=[wandb.keras.WandbCallback()],\n",
    "    )\n",
    "    end = time.time()\n",
    "    wandb.log({\"model_training_time (seconds)\": end - start})\n",
    "\n",
    "    loss, acc = model.evaluate(test_ds)\n",
    "    wandb.log({\"test_loss\": loss})\n",
    "    wandb.log({\"test_acc\": acc})\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a95b2",
   "metadata": {},
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590de87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RUNS = 10\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb5d2b-4ff7-41ae-bdba-6559623d4b47",
   "metadata": {},
   "source": [
    "## Training with fixed batch length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9ffd9-6446-4987-ac52-2c33a157238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(\"train\", BATCH_SIZE, preprocess_fixed_batch, True)\n",
    "valid_ds = get_dataset(\"val\", BATCH_SIZE, preprocess_fixed_batch, False)\n",
    "test_ds = get_dataset(\"test\", BATCH_SIZE, preprocess_fixed_batch, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d624092-1341-43f6-ab16-48642473bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"fixed-length-batching\"\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    run_name = f\"fixed-length-run:{i + 1}\"\n",
    "    train(train_ds, valid_ds, test_ds, NUM_EPOCHS, run_name, group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bcc099-fd26-4167-b4f5-2200bda269e3",
   "metadata": {},
   "source": [
    "## Training with variable batch length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b251cd",
   "metadata": {},
   "source": [
    "### Using TF Hub's BERT packer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a87002-e162-4e05-ad96-4b5af895f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(\"train\", BATCH_SIZE, preprocess_variable_batch_tfh, True)\n",
    "valid_ds = get_dataset(\"val\", BATCH_SIZE, preprocess_variable_batch_tfh, False)\n",
    "test_ds = get_dataset(\"test\", BATCH_SIZE, preprocess_variable_batch_tfh, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89894dea-1e54-4fb1-b377-1387c1196ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"variable-length-batching-tfh\"\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    run_name = f\"variable-length-run-tfh:{i + 1}\"\n",
    "    train(train_ds, valid_ds, test_ds, NUM_EPOCHS, run_name, group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6cb256",
   "metadata": {},
   "source": [
    "### Using custom BERT packer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d23cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(\"train\", BATCH_SIZE, preprocess_variable_batch_cust, True)\n",
    "valid_ds = get_dataset(\"val\", BATCH_SIZE, preprocess_variable_batch_cust, False)\n",
    "test_ds = get_dataset(\"test\", BATCH_SIZE, preprocess_variable_batch_cust, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f27946",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"variable-length-batching-cust\"\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    run_name = f\"variable-length-run-cust:{i + 1}\"\n",
    "    train(train_ds, valid_ds, test_ds, NUM_EPOCHS, run_name, group_name)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m84",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m84"
  },
  "interpreter": {
   "hash": "20d99275fbeb957608cf5adaee64ff23d07ebc4078dd173ca4cbf341a3a79b45"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
