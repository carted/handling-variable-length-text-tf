{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe6f857",
   "metadata": {},
   "source": [
    "## Training a Shallow Text Classifier with TFIDF Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e9e42",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/carted/handling-variable-length-text-tf/blob/main/bigram-tfidf-shallow-mlp.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/carted/handling-variable-length-text-tf/blob/main/bigram-tfidf-shallow-mlp.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775707b1",
   "metadata": {
    "id": "775707b1"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf62c31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbf62c31",
    "outputId": "510773bd-f630-42d2-ea44-d0f260096944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1CvkRnGC8b_-n1NcbwcwxcIq7SusmDMb5\n",
      "To: /content/train_data.txt\n",
      "100% 35.4M/35.4M [00:00<00:00, 165MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1h1evGF5NVi2p8RoWxl8xhpOod0ZN_-ky\n",
      "To: /content/test_data_solution.txt\n",
      "100% 35.4M/35.4M [00:00<00:00, 165MB/s] \n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1CvkRnGC8b_-n1NcbwcwxcIq7SusmDMb5 -O train_data.txt\n",
    "!gdown --id 1h1evGF5NVi2p8RoWxl8xhpOod0ZN_-ky -O test_data_solution.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9010888d",
   "metadata": {
    "id": "9010888d"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718dc6e4",
   "metadata": {
    "id": "718dc6e4"
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f48e4f",
   "metadata": {
    "id": "10f48e4f"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"train_data.txt\",\n",
    "    engine=\"python\",\n",
    "    sep=\" ::: \",\n",
    "    names=[\"id\", \"movie\", \"genre\", \"summary\"],\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    \"test_data_solution.txt\",\n",
    "    engine=\"python\",\n",
    "    sep=\" ::: \",\n",
    "    names=[\"id\", \"movie\", \"genre\", \"summary\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a143a",
   "metadata": {
    "id": "b51a143a"
   },
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10abec9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e10abec9",
    "outputId": "9309a99d-5da6-466c-e1cb-e987e57a867f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 48792.\n",
      "Number of validation samples: 5422.\n",
      "Number of test examples: 54200.\n"
     ]
    }
   ],
   "source": [
    "# Split the data using train_test_split from sklearn\n",
    "train_shuffled = train_df.sample(frac=1)\n",
    "train_df_new, val_df = train_test_split(train_shuffled, test_size=0.1)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_df_new)}.\")\n",
    "print(f\"Number of validation samples: {len(val_df)}.\")\n",
    "print(f\"Number of test examples: {len(test_df)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2f49e2",
   "metadata": {
    "id": "0d2f49e2"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "BC9z4bNaCmMb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BC9z4bNaCmMb",
    "outputId": "c4d3a066-b007-42d0-ca52-dda1dc12ae7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1829"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new[\"total_words\"] = train_df_new[\"summary\"].apply(lambda x: len(x.split()))\n",
    "max_seqlen = train_df_new[\"total_words\"].max()\n",
    "max_seqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583d5ba9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "583d5ba9",
    "outputId": "7d07fb54-c6a2-46c7-f951-402b0047da1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]',\n",
       " 'short',\n",
       " 'sci-fi',\n",
       " 'documentary',\n",
       " 'drama',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'adult',\n",
       " 'romance',\n",
       " 'adventure',\n",
       " 'western',\n",
       " 'family',\n",
       " 'talk-show',\n",
       " 'news',\n",
       " 'horror',\n",
       " 'history',\n",
       " 'music',\n",
       " 'sport',\n",
       " 'war',\n",
       " 'animation',\n",
       " 'game-show',\n",
       " 'action',\n",
       " 'crime',\n",
       " 'reality-tv',\n",
       " 'mystery',\n",
       " 'musical',\n",
       " 'fantasy',\n",
       " 'biography']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer = keras.layers.TextVectorization(max_tokens=max_seqlen, ngrams=2, output_mode=\"tf_idf\")\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    text_vectorizer.adapt(train_df_new[\"summary\"])\n",
    "\n",
    "label_encoder = keras.layers.StringLookup(vocabulary=train_df_new[\"genre\"].unique())\n",
    "label_encoder.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ca175b",
   "metadata": {
    "id": "66ca175b"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def prepare_dataset(dataframe):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dataframe[\"summary\"], dataframe[\"genre\"])\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(\n",
    "        lambda summaries, genres: (text_vectorizer(summaries), label_encoder(genres)),\n",
    "        num_parallel_calls=auto,\n",
    "    ).cache()\n",
    "    return dataset.prefetch(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6528c33a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6528c33a",
    "outputId": "94898329-cfd8-408d-badf-8d724fd8d0ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1829) (64,)\n"
     ]
    }
   ],
   "source": [
    "training_dataset = prepare_dataset(train_df_new)\n",
    "validation_dataset = prepare_dataset(val_df)\n",
    "test_dataset = prepare_dataset(test_df)\n",
    "\n",
    "\n",
    "for sequences, labels in training_dataset.take(1):\n",
    "    print(sequences.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zgLE_iKQAd7C",
   "metadata": {
    "id": "zgLE_iKQAd7C"
   },
   "source": [
    "## Model utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "869d3da1",
   "metadata": {
    "id": "869d3da1"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    shallow_mlp_model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(512, activation=\"relu\"),\n",
    "            keras.layers.Dense(256, activation=\"relu\"),\n",
    "            keras.layers.Dense(label_encoder.vocabulary_size(), activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return shallow_mlp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Zw10Mxd0AfRv",
   "metadata": {
    "id": "Zw10Mxd0AfRv"
   },
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63f6039d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63f6039d",
    "outputId": "3352b60b-4c15-4e9f-ccd8-4d8489a814c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "763/763 [==============================] - 3s 3ms/step - loss: 2.1269 - accuracy: 0.4803 - val_loss: 1.6482 - val_accuracy: 0.5378\n",
      "Epoch 2/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 1.4933 - accuracy: 0.5595 - val_loss: 1.5942 - val_accuracy: 0.5397\n",
      "Epoch 3/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 1.2850 - accuracy: 0.6037 - val_loss: 1.6945 - val_accuracy: 0.5284\n",
      "Epoch 4/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 1.1200 - accuracy: 0.6457 - val_loss: 1.7306 - val_accuracy: 0.5330\n",
      "Epoch 5/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.9507 - accuracy: 0.6941 - val_loss: 1.8665 - val_accuracy: 0.5059\n",
      "Epoch 6/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.8176 - accuracy: 0.7357 - val_loss: 2.1472 - val_accuracy: 0.4921\n",
      "Epoch 7/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.7085 - accuracy: 0.7665 - val_loss: 2.5042 - val_accuracy: 0.5033\n",
      "Epoch 8/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.5982 - accuracy: 0.8028 - val_loss: 2.4998 - val_accuracy: 0.4875\n",
      "Epoch 9/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.5017 - accuracy: 0.8324 - val_loss: 2.5644 - val_accuracy: 0.4734\n",
      "Epoch 10/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.4258 - accuracy: 0.8585 - val_loss: 3.0435 - val_accuracy: 0.4576\n",
      "Epoch 11/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.3781 - accuracy: 0.8763 - val_loss: 3.1685 - val_accuracy: 0.4941\n",
      "Epoch 12/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.3177 - accuracy: 0.8942 - val_loss: 3.5111 - val_accuracy: 0.4941\n",
      "Epoch 13/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.2762 - accuracy: 0.9099 - val_loss: 3.6547 - val_accuracy: 0.4769\n",
      "Epoch 14/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.2394 - accuracy: 0.9228 - val_loss: 3.9069 - val_accuracy: 0.4769\n",
      "Epoch 15/60\n",
      "763/763 [==============================] - 2s 3ms/step - loss: 0.2040 - accuracy: 0.9331 - val_loss: 4.0917 - val_accuracy: 0.4915\n",
      "Epoch 16/60\n",
      "763/763 [==============================] - 2s 3ms/step - loss: 0.1834 - accuracy: 0.9417 - val_loss: 4.2465 - val_accuracy: 0.4808\n",
      "Epoch 17/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1504 - accuracy: 0.9518 - val_loss: 4.6064 - val_accuracy: 0.4840\n",
      "Epoch 18/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1472 - accuracy: 0.9525 - val_loss: 4.7535 - val_accuracy: 0.4801\n",
      "Epoch 19/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1627 - accuracy: 0.9494 - val_loss: 4.8439 - val_accuracy: 0.4906\n",
      "Epoch 20/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1534 - accuracy: 0.9515 - val_loss: 5.3002 - val_accuracy: 0.4860\n",
      "Epoch 21/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1522 - accuracy: 0.9517 - val_loss: 5.1882 - val_accuracy: 0.4882\n",
      "Epoch 22/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1332 - accuracy: 0.9570 - val_loss: 5.3140 - val_accuracy: 0.4793\n",
      "Epoch 23/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1226 - accuracy: 0.9621 - val_loss: 5.5203 - val_accuracy: 0.4661\n",
      "Epoch 24/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1351 - accuracy: 0.9587 - val_loss: 5.7630 - val_accuracy: 0.4611\n",
      "Epoch 25/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1202 - accuracy: 0.9622 - val_loss: 5.5442 - val_accuracy: 0.4650\n",
      "Epoch 26/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1051 - accuracy: 0.9672 - val_loss: 6.1580 - val_accuracy: 0.4919\n",
      "Epoch 27/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1149 - accuracy: 0.9647 - val_loss: 6.3746 - val_accuracy: 0.4659\n",
      "Epoch 28/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1096 - accuracy: 0.9668 - val_loss: 6.5307 - val_accuracy: 0.4696\n",
      "Epoch 29/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1075 - accuracy: 0.9663 - val_loss: 6.6217 - val_accuracy: 0.4860\n",
      "Epoch 30/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1009 - accuracy: 0.9689 - val_loss: 6.4920 - val_accuracy: 0.4768\n",
      "Epoch 31/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1069 - accuracy: 0.9678 - val_loss: 6.4422 - val_accuracy: 0.4959\n",
      "Epoch 32/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0999 - accuracy: 0.9702 - val_loss: 6.8128 - val_accuracy: 0.4653\n",
      "Epoch 33/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0985 - accuracy: 0.9708 - val_loss: 6.6713 - val_accuracy: 0.4675\n",
      "Epoch 34/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0885 - accuracy: 0.9734 - val_loss: 6.9721 - val_accuracy: 0.4685\n",
      "Epoch 35/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0867 - accuracy: 0.9735 - val_loss: 6.9272 - val_accuracy: 0.4917\n",
      "Epoch 36/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0956 - accuracy: 0.9722 - val_loss: 7.1589 - val_accuracy: 0.4956\n",
      "Epoch 37/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.9752 - val_loss: 7.2681 - val_accuracy: 0.4958\n",
      "Epoch 38/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0897 - accuracy: 0.9743 - val_loss: 7.3087 - val_accuracy: 0.4917\n",
      "Epoch 39/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0962 - accuracy: 0.9726 - val_loss: 7.4859 - val_accuracy: 0.4932\n",
      "Epoch 40/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0811 - accuracy: 0.9766 - val_loss: 7.0348 - val_accuracy: 0.4823\n",
      "Epoch 41/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.9762 - val_loss: 7.2561 - val_accuracy: 0.4849\n",
      "Epoch 42/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0984 - accuracy: 0.9730 - val_loss: 7.4048 - val_accuracy: 0.4875\n",
      "Epoch 43/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0875 - accuracy: 0.9752 - val_loss: 7.2045 - val_accuracy: 0.4908\n",
      "Epoch 44/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0657 - accuracy: 0.9800 - val_loss: 7.5468 - val_accuracy: 0.4889\n",
      "Epoch 45/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0759 - accuracy: 0.9778 - val_loss: 7.4829 - val_accuracy: 0.4817\n",
      "Epoch 46/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0750 - accuracy: 0.9792 - val_loss: 7.7399 - val_accuracy: 0.4762\n",
      "Epoch 47/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.9769 - val_loss: 7.4293 - val_accuracy: 0.4757\n",
      "Epoch 48/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.1009 - accuracy: 0.9732 - val_loss: 8.0313 - val_accuracy: 0.4803\n",
      "Epoch 49/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.9773 - val_loss: 8.2462 - val_accuracy: 0.4847\n",
      "Epoch 50/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.9771 - val_loss: 8.1154 - val_accuracy: 0.4900\n",
      "Epoch 51/60\n",
      "763/763 [==============================] - 2s 3ms/step - loss: 0.0667 - accuracy: 0.9809 - val_loss: 8.3821 - val_accuracy: 0.4692\n",
      "Epoch 52/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0739 - accuracy: 0.9790 - val_loss: 8.2407 - val_accuracy: 0.4854\n",
      "Epoch 53/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0713 - accuracy: 0.9811 - val_loss: 8.0732 - val_accuracy: 0.4766\n",
      "Epoch 54/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0681 - accuracy: 0.9813 - val_loss: 8.5076 - val_accuracy: 0.4849\n",
      "Epoch 55/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0750 - accuracy: 0.9796 - val_loss: 8.4956 - val_accuracy: 0.4869\n",
      "Epoch 56/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0761 - accuracy: 0.9799 - val_loss: 8.7340 - val_accuracy: 0.4757\n",
      "Epoch 57/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0657 - accuracy: 0.9822 - val_loss: 8.7144 - val_accuracy: 0.4899\n",
      "Epoch 58/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0654 - accuracy: 0.9820 - val_loss: 8.6923 - val_accuracy: 0.4819\n",
      "Epoch 59/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0693 - accuracy: 0.9809 - val_loss: 8.9453 - val_accuracy: 0.4782\n",
      "Epoch 60/60\n",
      "763/763 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.9800 - val_loss: 8.7961 - val_accuracy: 0.4755\n",
      "847/847 [==============================] - 2s 2ms/step - loss: 9.1531 - accuracy: 0.4710\n",
      "Top-1 accuracy on the test set: 47.1%.\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "\n",
    "shallow_mlp_model = make_model()\n",
    "shallow_mlp_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = shallow_mlp_model.fit(\n",
    "    training_dataset, validation_data=validation_dataset, epochs=epochs\n",
    ")\n",
    "\n",
    "_, accuracy = shallow_mlp_model.evaluate(test_dataset)\n",
    "print(f\"Top-1 accuracy on the test set: {round(accuracy * 100, 2)}%.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "bigram-tfidf-shallow-mlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
