{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9010888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f48e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"./data/train_data.txt\",\n",
    "    engine=\"python\",\n",
    "    sep=\" ::: \",\n",
    "    names=[\"id\", \"movie\", \"genre\", \"summary\"],\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    \"./data/test_data_solution.txt\",\n",
    "    engine=\"python\",\n",
    "    sep=\" ::: \",\n",
    "    names=[\"id\", \"movie\", \"genre\", \"summary\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10abec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 48792.\n",
      "Number of validation samples: 5422.\n",
      "Number of test examples: 54200.\n"
     ]
    }
   ],
   "source": [
    "# Split the data using train_test_split from sklearn\n",
    "train_shuffled = train_df.sample(frac=1)\n",
    "train_df_new, val_df = train_test_split(train_shuffled, test_size=0.1)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_df_new)}.\")\n",
    "print(f\"Number of validation samples: {len(val_df)}.\")\n",
    "print(f\"Number of test examples: {len(test_df)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a1a1da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/d29z43w90kz6f4kbzv5c9m9r0000gn/T/ipykernel_63205/3522933202.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df_new[\"total_words\"] = train_df_new[\"summary\"].str.split().str.len()\n"
     ]
    }
   ],
   "source": [
    "train_df_new[\"total_words\"] = train_df_new[\"summary\"].str.split().str.len()\n",
    "vocabulary_size = int(train_df_new[\"total_words\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583d5ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 14:08:42.829672: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-20 14:08:42.879975: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[UNK]',\n",
       " 'short',\n",
       " 'sci-fi',\n",
       " 'documentary',\n",
       " 'drama',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'adult',\n",
       " 'romance',\n",
       " 'adventure',\n",
       " 'western',\n",
       " 'family',\n",
       " 'talk-show',\n",
       " 'news',\n",
       " 'horror',\n",
       " 'history',\n",
       " 'music',\n",
       " 'sport',\n",
       " 'war',\n",
       " 'animation',\n",
       " 'game-show',\n",
       " 'action',\n",
       " 'crime',\n",
       " 'reality-tv',\n",
       " 'mystery',\n",
       " 'musical',\n",
       " 'fantasy',\n",
       " 'biography']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer = keras.layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size, ngrams=2, output_mode=\"tf_idf\"\n",
    ")\n",
    "text_vectorizer.adapt(train_df_new[\"summary\"])\n",
    "\n",
    "label_encoder = keras.layers.StringLookup(vocabulary=train_df_new[\"genre\"].unique())\n",
    "label_encoder.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66ca175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def prepare_dataset(dataframe):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dataframe[\"summary\"], dataframe[\"genre\"])\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(\n",
    "        lambda summaries, genres: (text_vectorizer(summaries), label_encoder(genres)),\n",
    "        num_parallel_calls=auto,\n",
    "    )\n",
    "    return dataset.prefetch(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6528c33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n"
     ]
    }
   ],
   "source": [
    "training_dataset = prepare_dataset(train_df_new)\n",
    "validation_dataset = prepare_dataset(val_df)\n",
    "test_dataset = prepare_dataset(test_df)\n",
    "\n",
    "\n",
    "for sequences, labels in training_dataset.take(1):\n",
    "    print(sequences.shape[0], labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "869d3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    shallow_mlp_model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(512, activation=\"relu\"),\n",
    "            keras.layers.Dense(256, activation=\"relu\"),\n",
    "            keras.layers.Dense(label_encoder.vocabulary_size(), activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return shallow_mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f6039d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1525/1525 [==============================] - 10s 6ms/step - loss: 2.0431 - accuracy: 0.4848 - val_loss: 1.6110 - val_accuracy: 0.5404\n",
      "Epoch 2/20\n",
      "1525/1525 [==============================] - 10s 6ms/step - loss: 1.4535 - accuracy: 0.5661 - val_loss: 1.5726 - val_accuracy: 0.5465\n",
      "Epoch 3/20\n",
      "1525/1525 [==============================] - 10s 6ms/step - loss: 1.2403 - accuracy: 0.6117 - val_loss: 1.6681 - val_accuracy: 0.5411\n",
      "Epoch 4/20\n",
      "1525/1525 [==============================] - 10s 6ms/step - loss: 1.0412 - accuracy: 0.6642 - val_loss: 1.9029 - val_accuracy: 0.5190\n",
      "Epoch 5/20\n",
      "1525/1525 [==============================] - 10s 6ms/step - loss: 0.8513 - accuracy: 0.7218 - val_loss: 2.3080 - val_accuracy: 0.4930\n",
      "Epoch 6/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.7001 - accuracy: 0.7690 - val_loss: 2.4766 - val_accuracy: 0.5094\n",
      "Epoch 7/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.5809 - accuracy: 0.8070 - val_loss: 2.6020 - val_accuracy: 0.4856\n",
      "Epoch 8/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.4625 - accuracy: 0.8457 - val_loss: 2.8647 - val_accuracy: 0.4637\n",
      "Epoch 9/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.4133 - accuracy: 0.8626 - val_loss: 3.1482 - val_accuracy: 0.4554\n",
      "Epoch 10/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.3539 - accuracy: 0.8806 - val_loss: 3.7805 - val_accuracy: 0.5009\n",
      "Epoch 11/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.3175 - accuracy: 0.8950 - val_loss: 3.8973 - val_accuracy: 0.5072\n",
      "Epoch 12/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.2767 - accuracy: 0.9104 - val_loss: 4.1272 - val_accuracy: 0.4947\n",
      "Epoch 13/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.2457 - accuracy: 0.9205 - val_loss: 4.5031 - val_accuracy: 0.5052\n",
      "Epoch 14/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.2306 - accuracy: 0.9279 - val_loss: 4.4400 - val_accuracy: 0.5024\n",
      "Epoch 15/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.2235 - accuracy: 0.9297 - val_loss: 5.0511 - val_accuracy: 0.5044\n",
      "Epoch 16/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.2066 - accuracy: 0.9348 - val_loss: 5.1581 - val_accuracy: 0.4827\n",
      "Epoch 17/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.1771 - accuracy: 0.9440 - val_loss: 5.7959 - val_accuracy: 0.4867\n",
      "Epoch 18/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.1841 - accuracy: 0.9434 - val_loss: 6.1232 - val_accuracy: 0.4895\n",
      "Epoch 19/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.1823 - accuracy: 0.9456 - val_loss: 5.5085 - val_accuracy: 0.4841\n",
      "Epoch 20/20\n",
      "1525/1525 [==============================] - 9s 6ms/step - loss: 0.1864 - accuracy: 0.9461 - val_loss: 5.6974 - val_accuracy: 0.4954\n",
      "1694/1694 [==============================] - 2s 1ms/step - loss: 5.8079 - accuracy: 0.4892\n",
      "Top-1 accuracy on the test set: 48.92%.\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "shallow_mlp_model = make_model()\n",
    "shallow_mlp_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = shallow_mlp_model.fit(\n",
    "    training_dataset, validation_data=validation_dataset, epochs=epochs\n",
    ")\n",
    "\n",
    "_, accuracy = shallow_mlp_model.evaluate(test_dataset)\n",
    "print(f\"Top-1 accuracy on the test set: {round(accuracy * 100, 2)}%.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
