{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05df71d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91cb7d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"./data/train_data.txt\",\n",
    "    engine=\"python\",\n",
    "    sep=\" ::: \",\n",
    "    names=[\"id\", \"movie\", \"genre\", \"summary\"],\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    \"./data/test_data_solution.txt\",\n",
    "    engine=\"python\",\n",
    "    sep=\" ::: \",\n",
    "    names=[\"id\", \"movie\", \"genre\", \"summary\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "505d63df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oscar et la dame rose (2009)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cupid (1997)</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Young, Wild and Wonderful (1980)</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Secret Sin (1915)</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Unrecovered (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>The film's title refers not only to the un-rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                             movie     genre  \\\n",
       "0   1      Oscar et la dame rose (2009)     drama   \n",
       "1   2                      Cupid (1997)  thriller   \n",
       "2   3  Young, Wild and Wonderful (1980)     adult   \n",
       "3   4             The Secret Sin (1915)     drama   \n",
       "4   5            The Unrecovered (2007)     drama   \n",
       "\n",
       "                                             summary  \n",
       "0  Listening in to a conversation between his doc...  \n",
       "1  A brother and sister with a past incestuous re...  \n",
       "2  As the bus empties the students for their fiel...  \n",
       "3  To help their unemployed father make ends meet...  \n",
       "4  The film's title refers not only to the un-rec...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing training data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ba7b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 48792.\n",
      "Number of validation samples: 5422.\n",
      "Number of test examples: 54200.\n"
     ]
    }
   ],
   "source": [
    "# Split the data using train_test_split from sklearn\n",
    "train_shuffled = train_df.sample(frac=1)\n",
    "train_df_new, val_df = train_test_split(train_shuffled, test_size=0.1)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_df_new)}.\")\n",
    "print(f\"Number of validation samples: {len(val_df)}.\")\n",
    "print(f\"Number of test examples: {len(test_df)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff3c7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 11:02:20.802559: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer = keras.layers.TextVectorization()\n",
    "text_vectorizer.adapt(train_df_new[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fed20b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92,)\n",
      "(32,)\n",
      "(113,)\n",
      "(191,)\n",
      "(106,)\n",
      "(258,)\n",
      "(63,)\n",
      "(59,)\n",
      "(82,)\n",
      "(66,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(text_vectorizer(train_df_new[\"summary\"][i]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e205a3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/d29z43w90kz6f4kbzv5c9m9r0000gn/T/ipykernel_62311/1668209276.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df_new[\"total_words\"] = train_df_new[\"summary\"].str.split().str.len()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1829"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new[\"total_words\"] = train_df_new[\"summary\"].str.split().str.len()\n",
    "vocabulary_size = train_df_new[\"total_words\"].max()\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ca6593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]',\n",
       " 'short',\n",
       " 'sci-fi',\n",
       " 'documentary',\n",
       " 'drama',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'adult',\n",
       " 'romance',\n",
       " 'adventure',\n",
       " 'western',\n",
       " 'family',\n",
       " 'talk-show',\n",
       " 'news',\n",
       " 'horror',\n",
       " 'history',\n",
       " 'music',\n",
       " 'sport',\n",
       " 'war',\n",
       " 'animation',\n",
       " 'game-show',\n",
       " 'action',\n",
       " 'crime',\n",
       " 'reality-tv',\n",
       " 'mystery',\n",
       " 'musical',\n",
       " 'fantasy',\n",
       " 'biography']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = keras.layers.StringLookup(vocabulary=train_df_new[\"genre\"].unique())\n",
    "label_encoder.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb377606",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def preprocess_single_row(summary, label):\n",
    "    summary = text_vectorizer(summary)\n",
    "    label = label_encoder(label)\n",
    "    return summary, label\n",
    "\n",
    "\n",
    "def prepare_dataset(dataframe):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dataframe[\"summary\"].values, dataframe[\"genre\"].values)\n",
    "    )\n",
    "    dataset = dataset.map(preprocess_single_row, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.bucket_by_sequence_length(\n",
    "        element_length_func=lambda sequence, label: tf.shape(sequence)[0],\n",
    "        bucket_boundaries=[vocabulary_size],\n",
    "        bucket_batch_sizes=[batch_size, batch_size],\n",
    "    )\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e248539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 322)\n",
      "(32,)\n",
      "(32, 273)\n",
      "(32,)\n",
      "(32, 408)\n",
      "(32,)\n",
      "(32, 250)\n",
      "(32,)\n",
      "(32, 461)\n",
      "(32,)\n",
      "(32, 335)\n",
      "(32,)\n",
      "(32, 336)\n",
      "(32,)\n",
      "(32, 331)\n",
      "(32,)\n",
      "(32, 292)\n",
      "(32,)\n",
      "(32, 276)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "training_dataset = prepare_dataset(train_df_new)\n",
    "validation_dataset = prepare_dataset(val_df)\n",
    "test_dataset = prepare_dataset(test_df)\n",
    "\n",
    "\n",
    "for sample_batch in training_dataset.take(10):\n",
    "    print(sample_batch[0].shape)\n",
    "    print(sample_batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "613e6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "    x = keras.layers.Embedding(\n",
    "        input_dim=text_vectorizer.vocabulary_size(), output_dim=16\n",
    "    )(inputs)\n",
    "    x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    outputs = keras.layers.Dense(label_encoder.vocabulary_size(), activation=\"softmax\")(\n",
    "        x\n",
    "    )\n",
    "    shallow_mlp_model = keras.Model(inputs, outputs)\n",
    "    return shallow_mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e7e213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 16)          2270112   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               8704      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 28)                7196      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,417,340\n",
      "Trainable params: 2,417,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "make_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c1c4b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1525/1525 [==============================] - 27s 18ms/step - loss: 2.0849 - accuracy: 0.3692 - val_loss: 1.7864 - val_accuracy: 0.4707\n",
      "Epoch 2/5\n",
      "1525/1525 [==============================] - 25s 17ms/step - loss: 1.6488 - accuracy: 0.5000 - val_loss: 1.7372 - val_accuracy: 0.4821\n",
      "Epoch 3/5\n",
      "1525/1525 [==============================] - 25s 17ms/step - loss: 1.4246 - accuracy: 0.5651 - val_loss: 1.8281 - val_accuracy: 0.4841\n",
      "Epoch 4/5\n",
      "1525/1525 [==============================] - 25s 17ms/step - loss: 1.1737 - accuracy: 0.6438 - val_loss: 2.0186 - val_accuracy: 0.4928\n",
      "Epoch 5/5\n",
      "1525/1525 [==============================] - 25s 17ms/step - loss: 0.9570 - accuracy: 0.7091 - val_loss: 2.2016 - val_accuracy: 0.5011\n",
      "Model took 128.98 seconds to train.\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "shallow_mlp_model = make_model()\n",
    "shallow_mlp_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "history = shallow_mlp_model.fit(\n",
    "    training_dataset, validation_data=validation_dataset, epochs=epochs\n",
    ")\n",
    "end_time = time.time()\n",
    "print(f\"Model took {(end_time - start_time):.2f} seconds to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1c4464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1694/1694 [==============================] - 3s 2ms/step - loss: 2.1967 - accuracy: 0.49638 \n",
      "Top-1 accuracy on the test set: 49.63%.\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = shallow_mlp_model.evaluate(test_dataset)\n",
    "print(f\"Top-1 accuracy on the test set: {round(accuracy * 100, 2)}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a11e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = keras.layers.TextVectorization(output_sequence_length=1829)\n",
    "text_vectorizer.adapt(train_df_new[\"summary\"])\n",
    "\n",
    "\n",
    "def preprocess_fixed_length(summary, label):\n",
    "    summary = text_vectorizer(summary)\n",
    "    label = label_encoder(label)\n",
    "    return summary, label\n",
    "\n",
    "\n",
    "def prepare_dataset_fixed_length(dataframe):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dataframe[\"summary\"].values, dataframe[\"genre\"].values)\n",
    "    )\n",
    "    dataset = dataset.map(preprocess_fixed_length, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f850ee9",
   "metadata": {},
   "source": [
    "If we set `output_sequence_length=vocabulary_size` then it leads to:\n",
    "\n",
    "> ValueError: `output_sequence_length` must be either None or an integer when `output_mode` is 'int'. Received: output_sequence_length=1829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9d0070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1829)\n",
      "(32,)\n",
      "(32, 1829)\n",
      "(32,)\n",
      "(32, 1829)\n",
      "(32,)\n",
      "(32, 1829)\n",
      "(32,)\n",
      "(32, 1829)\n",
      "(32,)\n",
      "(32, 1829)\n",
      "(32,)\n",
      "(32, 1829)\n",
      "(32,)\n",
      "(32, 1829)\n",
      "(32,)\n",
      "(32, 1829)\n",
      "(32,)\n",
      "(32, 1829)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "training_dataset = prepare_dataset_fixed_length(train_df_new)\n",
    "validation_dataset = prepare_dataset_fixed_length(val_df)\n",
    "test_dataset = prepare_dataset_fixed_length(test_df)\n",
    "\n",
    "\n",
    "for sample_batch in training_dataset.take(10):\n",
    "    print(sample_batch[0].shape)\n",
    "    print(sample_batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "affd25d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1525/1525 [==============================] - 29s 19ms/step - loss: 2.3460 - accuracy: 0.2517 - val_loss: 2.2328 - val_accuracy: 0.3139\n",
      "Epoch 2/5\n",
      "1525/1525 [==============================] - 28s 18ms/step - loss: 2.0254 - accuracy: 0.3941 - val_loss: 1.9426 - val_accuracy: 0.4209\n",
      "Epoch 3/5\n",
      "1525/1525 [==============================] - 28s 18ms/step - loss: 1.7954 - accuracy: 0.4651 - val_loss: 1.7989 - val_accuracy: 0.4648\n",
      "Epoch 4/5\n",
      "1525/1525 [==============================] - 28s 18ms/step - loss: 1.6316 - accuracy: 0.5062 - val_loss: 1.7842 - val_accuracy: 0.4622\n",
      "Epoch 5/5\n",
      "1525/1525 [==============================] - 28s 18ms/step - loss: 1.5054 - accuracy: 0.5413 - val_loss: 1.8148 - val_accuracy: 0.4554\n",
      "Model took 141.83 seconds to train.\n"
     ]
    }
   ],
   "source": [
    "shallow_mlp_model = make_model()\n",
    "shallow_mlp_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "history = shallow_mlp_model.fit(\n",
    "    training_dataset, validation_data=validation_dataset, epochs=epochs\n",
    ")\n",
    "end_time = time.time()\n",
    "print(f\"Model took {(end_time - start_time):.2f} seconds to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9207b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1694/1694 [==============================] - 3s 2ms/step - loss: 1.8200 - accuracy: 0.4491\n",
      "Top-1 accuracy on the test set: 44.91%.\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = shallow_mlp_model.evaluate(test_dataset)\n",
    "print(f\"Top-1 accuracy on the test set: {round(accuracy * 100, 2)}%.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
