{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f943bf42",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9014279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Dict\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44377fcf",
   "metadata": {},
   "source": [
    "## Contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d42dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS_DIR = \"gs://variable-length-sequences-tf/tfrecords\"\n",
    "BERT_MAX_SEQLEN = 512\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126bde2",
   "metadata": {},
   "source": [
    "## TFRecord parsing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a40156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = {\n",
    "    \"summary\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_tokens\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_tokens_len\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "    \"label\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a5de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_composite(serialized, type_spec):\n",
    "    \"\"\"Parses a serialized Ragged features and retains the original structure.\"\"\"\n",
    "    serialized = tf.io.parse_tensor(serialized, tf.string)\n",
    "    component_specs = tf.nest.flatten(type_spec, expand_composites=True)\n",
    "    components = [\n",
    "        tf.io.parse_tensor(serialized[i], spec.dtype)\n",
    "        for i, spec in enumerate(component_specs)\n",
    "    ]\n",
    "    return tf.nest.pack_sequence_as(type_spec, components, expand_composites=True)\n",
    "\n",
    "\n",
    "def read_example(example):\n",
    "    \"\"\"Parses a single TFRecord file.\"\"\"\n",
    "    features = tf.io.parse_single_example(example, feature_descriptions)\n",
    "    features[\"summary_tokens\"] = deserialize_composite(\n",
    "        features.get(\"summary_tokens\"),\n",
    "        tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=2),\n",
    "    )\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d2384",
   "metadata": {},
   "source": [
    "## Preprocessing function for fixed length batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474df024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 13:03:24.881516: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-22 13:03:26.384307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38464 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
      "2021-12-22 13:03:27.104325: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest token sequence in the training split: 2947\n"
     ]
    }
   ],
   "source": [
    "# Find the longest sequence in the training set\n",
    "ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/train-*.tfrecord\")\n",
    "ds = tf.data.TFRecordDataset(ds).map(\n",
    "    lambda example: tf.io.parse_single_example(example, feature_descriptions)\n",
    ")\n",
    "max_seq_len = tf.cast(\n",
    "    tf.reduce_max([datum[\"summary_tokens_len\"] for datum in ds]), tf.int32\n",
    ")\n",
    "print(f\"Longest token sequence in the training split: {max_seq_len.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f067d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = hub.load(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "fixed_len_bert_packer = hub.KerasLayer(\n",
    "    preprocessor.bert_pack_inputs,\n",
    "    arguments={\"seq_length\": tf.minimum(max_seq_len + 2, BERT_MAX_SEQLEN)},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37448903",
   "metadata": {},
   "source": [
    "#### Note: We add 2 to the maximum length to account for the CLS and SEP tokens that would be added later by the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be99af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fixed_batch(batch):\n",
    "    \"\"\"Batch processing utility.\"\"\"\n",
    "\n",
    "    # Generating the inputs for the BERT model.\n",
    "    bert_packed_text = fixed_len_bert_packer(\n",
    "        [tf.squeeze(batch.pop(\"summary_tokens\"), axis=1)]\n",
    "    )\n",
    "\n",
    "    labels = batch.pop(\"label\")\n",
    "    return bert_packed_text, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fa686e",
   "metadata": {},
   "source": [
    "## Preprocessing function for variable length batching using the BERT packer from TF Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74f3ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_text_preprocessor(preprocessor_path: str) -> Callable:\n",
    "    \"\"\"Decorator to set the desired preprocessor for a\n",
    "        function from a TensorFlow Hub URL.\n",
    "\n",
    "    Arguments:\n",
    "        preprocessor_path {str} -- URL of the TF-Hub preprocessor.\n",
    "\n",
    "    Returns:\n",
    "        Callable -- A function with the `preprocessor` attribute set.\n",
    "    \"\"\"\n",
    "\n",
    "    def decoration(func: Callable):\n",
    "        # Loading the preprocessor from TF-Hub\n",
    "        preprocessor = hub.load(preprocessor_path)\n",
    "\n",
    "        # Setting an attribute called `preprocessor` to\n",
    "        # the passed function\n",
    "        func.preprocessor = preprocessor\n",
    "        return func\n",
    "\n",
    "    return decoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a4379e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@set_text_preprocessor(\n",
    "    preprocessor_path=\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    ")\n",
    "def preprocess_variable_batch_tfh(batch):\n",
    "    \"\"\"Batch processing utility.\"\"\"\n",
    "    text_tokens_max_len = tf.cast(\n",
    "        tf.math.reduce_max(batch[\"summary_tokens_len\"]),\n",
    "        dtype=tf.int32,\n",
    "    )\n",
    "\n",
    "    # Generating the inputs for the BERT model.\n",
    "    bert_input_packer = hub.KerasLayer(\n",
    "        preprocess_variable_batch_tfh.preprocessor.bert_pack_inputs,\n",
    "        arguments={\"seq_length\": tf.minimum(text_tokens_max_len + 2, BERT_MAX_SEQLEN)},\n",
    "    )\n",
    "    bert_packed_text = bert_input_packer(\n",
    "        [tf.squeeze(batch.pop(\"summary_tokens\"), axis=1)]\n",
    "    )\n",
    "\n",
    "    labels = batch.pop(\"label\")\n",
    "    return bert_packed_text, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb54e58",
   "metadata": {},
   "source": [
    "## Preprocessing function for variable length batching using a custom written BERT packer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b71aa7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_bert_inputs(\n",
    "    batch_tokens: tf.RaggedTensor,\n",
    "    batch_lens: tf.Tensor,\n",
    "    max_len: int = tf.constant(512),\n",
    ") -> Dict[str, tf.Tensor]:\n",
    "    \"\"\"Pack the tokens w.r.t BERT inputs.\"\"\"\n",
    "\n",
    "    # Remove the last ragged dimension\n",
    "    batch_tokens = tf.RaggedTensor.from_row_lengths(\n",
    "        batch_tokens.flat_values, batch_lens\n",
    "    )\n",
    "\n",
    "    # Calcuate batch size.\n",
    "    batch_size = tf.shape(batch_lens)[0]\n",
    "\n",
    "    # Define special token values (very specific to BERT).\n",
    "    CLS = 101\n",
    "    SEP = 102\n",
    "    PAD = 0\n",
    "\n",
    "    # Prepare the special tokens for concatenation.\n",
    "    batch_cls = tf.repeat(tf.constant([[CLS]]), batch_size, axis=0)\n",
    "    batch_cls = tf.RaggedTensor.from_tensor(batch_cls).with_row_splits_dtype(\n",
    "        batch_tokens.row_splits.dtype\n",
    "    )\n",
    "    batch_sep = tf.repeat(tf.constant([[SEP]]), batch_size, axis=0)\n",
    "    batch_sep = tf.RaggedTensor.from_tensor(batch_sep).with_row_splits_dtype(\n",
    "        batch_tokens.row_splits.dtype\n",
    "    )\n",
    "\n",
    "    # Truncate the sequences that are shorter than max_len.\n",
    "    max_batch_len = tf.minimum(tf.reduce_max(batch_lens) + 2, max_len)\n",
    "    truncated_tokens = batch_tokens[:, : max_batch_len - 2]\n",
    "\n",
    "    # Sandwich the truncated tokens in between the special tokens.\n",
    "    prepared_tokens = tf.concat([batch_cls, truncated_tokens, batch_sep], axis=1)\n",
    "\n",
    "    # Convert the tokens to a regular int32 tensor and pad the\n",
    "    # shorter sequences with PAD.\n",
    "    padded_tokens = prepared_tokens.to_tensor(PAD)\n",
    "\n",
    "    # Create the segment id tensor.\n",
    "    segment_ids = tf.zeros_like(padded_tokens)\n",
    "\n",
    "    # Create the input mask\n",
    "    mask = tf.sequence_mask(batch_lens + 2, max_batch_len, dtype=tf.int32)\n",
    "\n",
    "    ret = {\n",
    "        \"input_word_ids\": padded_tokens,\n",
    "        \"input_type_ids\": segment_ids,\n",
    "        \"input_mask\": mask,\n",
    "    }\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c39c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_variable_batch_cust(batch):\n",
    "    \"\"\"Batch processing utility.\"\"\"\n",
    "    text_token_lens = tf.cast(batch[\"summary_tokens_len\"], dtype=tf.int32)\n",
    "\n",
    "    # Generating the inputs for the BERT model.\n",
    "    bert_packed_text = prepare_bert_inputs(\n",
    "        tf.squeeze(batch[\"summary_tokens\"], axis=1), tf.reshape(text_token_lens, (-1,))\n",
    "    )\n",
    "    labels = batch.pop(\"label\")\n",
    "    return bert_packed_text, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20240ca5",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2287f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(\n",
    "    split: str, batch_size: int, batch_preprocessor: Callable, shuffle: bool\n",
    "):\n",
    "    \"\"\"Prepares tf.data.Dataset objects from TFRecords.\"\"\"\n",
    "    ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/{split}-*.tfrecord\")\n",
    "    ds = (\n",
    "        ds.interleave(\n",
    "            tf.data.TFRecordDataset,\n",
    "            cycle_length=tf.data.AUTOTUNE,\n",
    "            num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        )\n",
    "        .map(read_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "        .cache()\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(batch_size * 10)\n",
    "    ds = (\n",
    "        ds.batch(batch_size)\n",
    "        .map(batch_preprocessor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2aca18",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "816f420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_classifier(\n",
    "    encoder_path: str,\n",
    "    input_features: List[str],\n",
    "    train_encoder: bool,\n",
    "    proj_dim: int,\n",
    "    num_labels: int,\n",
    "):\n",
    "    \"\"\"Creates a simple classification model.\"\"\"\n",
    "    sentence_encoder = hub.KerasLayer(encoder_path)\n",
    "    sentence_encoder.trainable = train_encoder\n",
    "\n",
    "    inputs = {\n",
    "        feature_name: tf.keras.Input(shape=(None,), dtype=tf.int32, name=feature_name)\n",
    "        for feature_name in input_features\n",
    "    }\n",
    "\n",
    "    text_encodings = sentence_encoder(inputs)\n",
    "    projections = tf.keras.layers.Dense(proj_dim, activation=\"relu\")(\n",
    "        text_encodings[\"pooled_output\"]\n",
    "    )\n",
    "    probs = tf.keras.layers.Dense(num_labels, activation=\"softmax\")(projections)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc4f9d1",
   "metadata": {},
   "source": [
    "## Training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b5831bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_ds: tf.data.Dataset,\n",
    "    valid_ds: tf.data.Dataset,\n",
    "    test_ds: tf.data.Dataset,\n",
    "    num_epochs: int,\n",
    "    run_name: str,\n",
    "    group_name: str,\n",
    "):\n",
    "    tfhub_model_uri = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "    cmlm_inputs = [\"input_word_ids\", \"input_type_ids\", \"input_mask\"]\n",
    "    proj_dim = 128\n",
    "    num_labels = 27\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"batching-experiments\",\n",
    "        entity=\"carted\",\n",
    "        name=run_name,\n",
    "        group=group_name,\n",
    "    )\n",
    "\n",
    "    model = genre_classifier(tfhub_model_uri, cmlm_inputs, False, proj_dim, num_labels)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\"\n",
    "    )\n",
    "    start = time.time()\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=valid_ds,\n",
    "        callbacks=[wandb.keras.WandbCallback()],\n",
    "    )\n",
    "    end = time.time()\n",
    "    wandb.log({\"model_training_time (seconds)\": end - start})\n",
    "\n",
    "    loss, acc = model.evaluate(test_ds)\n",
    "    wandb.log({\"test_loss\": loss})\n",
    "    wandb.log({\"test_acc\": acc})\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a95b2",
   "metadata": {},
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "590de87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RUNS = 10\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb5d2b-4ff7-41ae-bdba-6559623d4b47",
   "metadata": {},
   "source": [
    "## Training with fixed length batch length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04d9ffd9-6446-4987-ac52-2c33a157238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(\"train\", BATCH_SIZE, preprocess_fixed_batch, True)\n",
    "valid_ds = get_dataset(\"val\", BATCH_SIZE, preprocess_fixed_batch, False)\n",
    "test_ds = get_dataset(\"test\", BATCH_SIZE, preprocess_fixed_batch, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d624092-1341-43f6-ab16-48642473bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcarted\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/carted/batching-experiments/runs/2cok8rb0\" target=\"_blank\">fixed-length-run:1</a></strong> to <a href=\"https://wandb.ai/carted/batching-experiments\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 13:05:56.383470: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763/763 [==============================] - 247s 304ms/step - loss: 1.5209 - accuracy: 0.5629 - val_loss: 1.2545 - val_accuracy: 0.6094\n",
      "847/847 [==============================] - 231s 272ms/step - loss: 1.2699 - accuracy: 0.6070\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3731... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 419.04MB of 419.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>model_training_time (seconds)</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5629</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.25453</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.52085</td></tr><tr><td>model_training_time (seconds)</td><td>247.79806</td></tr><tr><td>test_acc</td><td>0.60705</td></tr><tr><td>test_loss</td><td>1.26989</td></tr><tr><td>val_accuracy</td><td>0.60937</td></tr><tr><td>val_loss</td><td>1.25453</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">fixed-length-run:1</strong>: <a href=\"https://wandb.ai/carted/batching-experiments/runs/2cok8rb0\" target=\"_blank\">https://wandb.ai/carted/batching-experiments/runs/2cok8rb0</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211222_130523-2cok8rb0/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_name = \"fixed-length-batching\"\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    run_name = f\"fixed-length-run:{i + 1}\"\n",
    "    train(train_ds, valid_ds, test_ds, NUM_EPOCHS, run_name, group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bcc099-fd26-4167-b4f5-2200bda269e3",
   "metadata": {},
   "source": [
    "## Training with variable batch length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b251cd",
   "metadata": {},
   "source": [
    "### Using TF Hub's BERT packer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2a87002-e162-4e05-ad96-4b5af895f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(\"train\", BATCH_SIZE, preprocess_variable_batch_tfh, True)\n",
    "valid_ds = get_dataset(\"val\", BATCH_SIZE, preprocess_variable_batch_tfh, False)\n",
    "test_ds = get_dataset(\"test\", BATCH_SIZE, preprocess_variable_batch_tfh, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89894dea-1e54-4fb1-b377-1387c1196ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/carted/batching-experiments/runs/3lpkutuy\" target=\"_blank\">variable-length-run-tfh:1</a></strong> to <a href=\"https://wandb.ai/carted/batching-experiments\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763/763 [==============================] - 218s 270ms/step - loss: 1.5056 - accuracy: 0.5638 - val_loss: 1.2450 - val_accuracy: 0.6070\n",
      "847/847 [==============================] - 204s 240ms/step - loss: 1.2566 - accuracy: 0.6118\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5449... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.40MB of 0.40MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>model_training_time (seconds)</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.56384</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.24495</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.50562</td></tr><tr><td>model_training_time (seconds)</td><td>219.71044</td></tr><tr><td>test_acc</td><td>0.61179</td></tr><tr><td>test_loss</td><td>1.25656</td></tr><tr><td>val_accuracy</td><td>0.60697</td></tr><tr><td>val_loss</td><td>1.24495</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">variable-length-run-tfh:1</strong>: <a href=\"https://wandb.ai/carted/batching-experiments/runs/3lpkutuy\" target=\"_blank\">https://wandb.ai/carted/batching-experiments/runs/3lpkutuy</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211222_131349-3lpkutuy/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_name = \"variable-length-batching-tfh\"\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    run_name = f\"variable-length-run-tfh:{i + 1}\"\n",
    "    train(train_ds, valid_ds, test_ds, NUM_EPOCHS, run_name, group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6cb256",
   "metadata": {},
   "source": [
    "### Using custom BERT packer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51d23cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(\"train\", BATCH_SIZE, preprocess_variable_batch_cust, True)\n",
    "valid_ds = get_dataset(\"val\", BATCH_SIZE, preprocess_variable_batch_cust, False)\n",
    "test_ds = get_dataset(\"test\", BATCH_SIZE, preprocess_variable_batch_cust, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38f27946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/carted/batching-experiments/runs/1ikpq9pp\" target=\"_blank\">variable-length-run-cust:1</a></strong> to <a href=\"https://wandb.ai/carted/batching-experiments\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763/763 [==============================] - 217s 268ms/step - loss: 1.5171 - accuracy: 0.5641 - val_loss: 1.2276 - val_accuracy: 0.6199\n",
      "847/847 [==============================] - 206s 243ms/step - loss: 1.2440 - accuracy: 0.6196\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10889... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 419.04MB of 419.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>model_training_time (seconds)</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.56413</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.22758</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.51708</td></tr><tr><td>model_training_time (seconds)</td><td>218.72235</td></tr><tr><td>test_acc</td><td>0.61965</td></tr><tr><td>test_loss</td><td>1.24397</td></tr><tr><td>val_accuracy</td><td>0.61988</td></tr><tr><td>val_loss</td><td>1.22758</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">variable-length-run-cust:1</strong>: <a href=\"https://wandb.ai/carted/batching-experiments/runs/1ikpq9pp\" target=\"_blank\">https://wandb.ai/carted/batching-experiments/runs/1ikpq9pp</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211222_134233-1ikpq9pp/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_name = \"variable-length-batching-cust\"\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    run_name = f\"variable-length-run-cust:{i + 1}\"\n",
    "    train(train_ds, valid_ds, test_ds, NUM_EPOCHS, run_name, group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5348ba0b-3620-44e3-a709-c947a27d646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo shutdown now"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m84",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m84"
  },
  "interpreter": {
   "hash": "20d99275fbeb957608cf5adaee64ff23d07ebc4078dd173ca4cbf341a3a79b45"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
