{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f943bf42",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9014279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as tft\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44377fcf",
   "metadata": {},
   "source": [
    "## Contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d42dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS_DIR = \"gs://variable-length-sequences-tf/tfrecords-sentence-splitter\"\n",
    "BERT_MAX_SEQLEN = 512\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126bde2",
   "metadata": {},
   "source": [
    "## TFRecord parsing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a40156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = {\n",
    "    \"summary\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_tokens\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_sentence_indices\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"summary_num_sentences\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "    \"summary_tokens_len\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    \"label\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a5de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_composite(\n",
    "    serialized: bytes, type_spec: tf.RaggedTensorSpec\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Deserializes a serialised ragged tensor.\"\"\"\n",
    "\n",
    "    serialized = tf.io.parse_tensor(serialized, tf.string)\n",
    "    component_specs = tf.nest.flatten(type_spec, expand_composites=True)\n",
    "    components = [\n",
    "        tf.io.parse_tensor(serialized[i], spec.dtype)\n",
    "        for i, spec in enumerate(component_specs)\n",
    "    ]\n",
    "    return tf.nest.pack_sequence_as(type_spec, components, expand_composites=True)\n",
    "\n",
    "\n",
    "def read_example(example):\n",
    "    \"\"\"Parses a single TFRecord file.\"\"\"\n",
    "    features = tf.io.parse_single_example(example, feature_descriptions)\n",
    "    features[\"summary_tokens\"] = deserialize_composite(\n",
    "        features.get(\"summary_tokens\"),\n",
    "        tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=2),\n",
    "    )\n",
    "    features[\"summary_sentence_indices\"] = deserialize_composite(\n",
    "        features.get(\"summary_sentence_indices\"),\n",
    "        tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=1),\n",
    "    )\n",
    "    features[\"summary_tokens_len\"] = deserialize_composite(\n",
    "        features.get(\"summary_tokens_len\"),\n",
    "        tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=1),\n",
    "    )\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6c4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInputUtils:\n",
    "    def __init__(\n",
    "        self,\n",
    "        bert_preprocessor_path: str = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
    "        encoder_max_seqlen: int = BERT_MAX_SEQLEN,\n",
    "    ):\n",
    "        \"\"\"Initializes a BERT model input preprocessing utility class.\"\"\"\n",
    "        self.bert_preprocessor_path = bert_preprocessor_path\n",
    "        self.preprocessor_module = hub.load(bert_preprocessor_path)\n",
    "        self.encoder_max_seqlen = encoder_max_seqlen\n",
    "\n",
    "    def init_packer_and_pack_inputs(\n",
    "        self, batch_tokens: tf.Tensor, batch_token_lens: tf.Tensor\n",
    "    ) -> tf.Tensor:\n",
    "        \"\"\"Prepares inputs for the BERT encoder.\"\"\"\n",
    "        max_token_len = tf.reduce_max(batch_token_lens)\n",
    "        packer = hub.KerasLayer(\n",
    "            self.preprocessor_module.bert_pack_inputs,\n",
    "            arguments={\n",
    "                \"seq_length\": tf.math.minimum(max_token_len, self.encoder_max_seqlen)\n",
    "            },\n",
    "        )\n",
    "        return packer([batch_tokens])\n",
    "\n",
    "    def unravel_ragged_batch(self, ragged_batch, ragged_idx, batch_lens, batch_size):\n",
    "        \"\"\"Flattens out a batch of ragged tensors by one level.\"\"\"\n",
    "        # create indices for each tensor in the batch\n",
    "        # for entries which have multiple ragged tensors, repeat their\n",
    "        # index once for each tensor in the entry\n",
    "        batch_idx = tf.repeat(tf.range(batch_size), batch_lens, axis=0)\n",
    "\n",
    "        # calculate length of the unravelled batch\n",
    "        unravelled_len = tf.reduce_sum(batch_lens)\n",
    "\n",
    "        # create a vector with alternating batch index and ragged tensor index\n",
    "        gather_nd_idx = tf.dynamic_stitch(\n",
    "            indices=[\n",
    "                tf.range(0, (unravelled_len * 2) - 1, 2, dtype=tf.int32),\n",
    "                tf.range(1, unravelled_len * 2, 2, dtype=tf.int32),\n",
    "            ],\n",
    "            data=[batch_idx, ragged_idx.flat_values],\n",
    "        )\n",
    "\n",
    "        # reshape the vector to obtain a unravelled_len x 2 matrix of indices\n",
    "        gather_nd_idx = tf.reshape(gather_nd_idx, shape=[-1, 2])\n",
    "\n",
    "        # obtain the flattened ragged batch using the index matrix\n",
    "        unravelled_tensors = tf.gather_nd(\n",
    "            ragged_batch, indices=gather_nd_idx, batch_dims=0\n",
    "        )\n",
    "\n",
    "        return unravelled_tensors\n",
    "\n",
    "    def get_bert_inputs(self, batch, batch_size):\n",
    "        \"\"\"Generates padded BERT inputs for a given batch of tokenied\n",
    "        text features.\"\"\"\n",
    "        # flatten out the RaggedTensor token batch.\n",
    "        tokens = self.unravel_ragged_batch(\n",
    "            batch.pop(\"summary_tokens\"),\n",
    "            batch.pop(\"summary_sentence_indices\"),\n",
    "            batch[\"summary_num_sentences\"],\n",
    "            batch_size,\n",
    "        )\n",
    "        # obtain the BERT inputs\n",
    "        batch[\"summary_tokens\"] = tokens\n",
    "        bert_inputs = self.init_packer_and_pack_inputs(\n",
    "            tokens, batch.pop(\"summary_tokens_len\").flat_values\n",
    "        )\n",
    "        return bert_inputs\n",
    "\n",
    "    def preprocess_batch(self, batch: Dict[str, tf.Tensor]):\n",
    "        \"\"\"Applies batch level transformations to the data.\"\"\"\n",
    "        batch_size = tf.shape(batch[\"label\"])[0]\n",
    "\n",
    "        # generate padded BERT inputs for all the text features\n",
    "        batch[\"bert_inputs\"] = self.get_bert_inputs(batch, batch_size)\n",
    "\n",
    "        label = batch.pop(\"label\")\n",
    "        return batch, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20240ca5",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f378ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 08:44:09.287371: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-16 08:44:10.815284: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "input_utils = ModelInputUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2287f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(split, batch_size, shuffle):\n",
    "    \"\"\"Prepares tf.data.Dataset objects from TFRecords.\"\"\"\n",
    "    ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/{split}-*.tfrecord\")\n",
    "    ds = ds.interleave(\n",
    "        tf.data.TFRecordDataset, cycle_length=3, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    ds = ds.map(\n",
    "        read_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False\n",
    "    ).cache()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(batch_size * 10)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.map(input_utils.preprocess_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350ec5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(\"train\", BATCH_SIZE, True)\n",
    "# valid_ds = get_dataset(\"val\", BATCH_SIZE, False)\n",
    "# test_ds = get_dataset(\"test\", BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3610027f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 08:44:23.278668: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.502315: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568683: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568712: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568761: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568783: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568805: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568824: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568837: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568856: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568872: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568882: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568892: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568900: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.568971: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569021: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569039: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569070: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569089: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569110: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569128: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569149: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569163: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569178: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569193: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569202: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569219: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569236: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569250: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569258: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569273: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569291: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:44:23.569315: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Key: summary_num_sentences.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z_/d29z43w90kz6f4kbzv5c9m9r0000gn/T/ipykernel_50164/2890310942.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Key: summary_num_sentences.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "for features, labels in train_ds.take(1):\n",
    "    print(features.keys())\n",
    "    print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e69cf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.Dataset.list_files(f\"{TFRECORDS_DIR}/train-*.tfrecord\")\n",
    "raw_dataset = tf.data.TFRecordDataset(ds)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a493dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 20\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"summary\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"After his defeat in the original Star Fox, the game\\'s antagonist, Andross, returns to the Lylat system and launches an all-out attack against Corneria, using his new fleet of battleships and giant missiles launched from hidden bases to destroy the planet. General Pepper again calls upon the Star Fox team for help. Armed with new custom Arwings, a Mothership, and two new recruits (Miyu, a lynx, and Fay, a dog), the Star Fox team sets out to defend Corneria by destroying Andross\\'s forces before they can inflict critical damage on the planet. Along the way, Star Fox must also combat giant boss enemies, bases on planets throughout the Lylat system, members of the Star Wolf team and finally Andross himself.\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"summary_num_sentences\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 54\n",
      "        value: 12\n",
      "        value: 58\n",
      "        value: 35\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"summary_sentence_indices\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\007\\022\\004\\022\\002\\010\\002B\\032\\010\\003\\022\\004\\022\\002\\010\\004\\\"\\020\\000\\000\\000\\000\\001\\000\\000\\000\\002\\000\\000\\000\\003\\000\\000\\000B\\032\\010\\t\\022\\004\\022\\002\\010\\002\\\"\\020\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"summary_tokens\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\007\\022\\004\\022\\002\\010\\003B\\210\\005\\010\\003\\022\\005\\022\\003\\010\\237\\001\\\"\\374\\004\\374\\007\\000\\000\\332\\007\\000\\000:\\020\\000\\000\\317\\007\\000\\000\\314\\007\\000\\000\\202\\t\\000\\000\\254\\n\\000\\000C\\021\\000\\000\\362\\003\\000\\000\\314\\007\\000\\000\\240\\010\\000\\000\\355\\003\\000\\000\\037\\004\\000\\000\\343C\\000\\000\\362\\003\\000\\000\\316\\007\\000\\000}d\\000\\000\\362\\003\\000\\000\\023\\026\\000\\000\\320\\007\\000\\000\\314\\007\\000\\000\\030\\004\\000\\000\\207]\\000\\0006\\010\\000\\000\\363\\010\\000\\000\\316\\007\\000\\000-J\\000\\000\\343\\007\\000\\000\\363\\007\\000\\000\\363\\003\\000\\000\\371\\007\\000\\000F\\013\\000\\000B\\010\\000\\000\\\\\\r\\000\\000a\\t\\000\\000\\362\\003\\000\\000\\256\\t\\000\\000\\332\\007\\000\\000\\377\\007\\000\\000J\\020\\000\\000\\315\\007\\000\\000OS\\000\\000\\316\\007\\000\\000\\230\\023\\000\\000?*\\000\\000>\\r\\000\\000\\335\\007\\000\\000\\237\\023\\000\\000\\320\\036\\000\\000\\320\\007\\000\\000\\221\\027\\000\\000\\314\\007\\000\\000\\246\\022\\000\\000\\364\\003\\000\\000\\274\\010\\000\\000--\\000\\000i\\010\\000\\000g\\021\\000\\000\\034\\n\\000\\000\\314\\007\\000\\000\\254\\n\\000\\000C\\021\\000\\000X\\010\\000\\000\\325\\007\\000\\000Y\\t\\000\\000\\364\\003\\000\\000\\261\\020\\000\\000\\327\\007\\000\\000\\377\\007\\000\\000\\355\\035\\000\\000B/\\000\\000p$\\000\\000\\337\\007\\000\\000\\362\\003\\000\\000\\r\\004\\000\\000\\004*\\000\\000\\345\\025\\000\\000\\362\\003\\000\\000\\316\\007\\000\\000\\000\\010\\000\\000\\377\\007\\000\\000\\260:\\000\\000\\356\\003\\000\\000\\323\\n\\000\\000\\021)\\000\\000\\362\\003\\000\\000\\r\\004\\000\\000lX\\000\\000\\362\\003\\000\\000\\316\\007\\000\\000\\241Z\\000\\000\\362\\003\\000\\000\\r\\004\\000\\000;\\017\\000\\000\\357\\003\\000\\000\\362\\003\\000\\000\\314\\007\\000\\000\\254\\n\\000\\000C\\021\\000\\000X\\010\\000\\000\\250\\021\\000\\000\\371\\007\\000\\000\\320\\007\\000\\000I\\033\\000\\000\\\\\\r\\000\\000a\\t\\000\\000\\333\\007\\000\\000v&\\000\\000\\316\\007\\000\\000}d\\000\\000\\355\\003\\000\\000\\037\\004\\000\\000\\275\\n\\000\\000\\035\\010\\000\\000\\353\\007\\000\\000\\020\\010\\000\\000\\317\\007\\000\\000ur\\000\\000[\\020\\000\\000\\325\\017\\000\\000\\326\\007\\000\\000\\314\\007\\000\\000\\246\\022\\000\\000\\364\\003\\000\\000\\307\\010\\000\\000\\314\\007\\000\\000N\\010\\000\\000\\362\\003\\000\\000\\254\\n\\000\\000C\\021\\000\\000\\212\\t\\000\\000\\364\\007\\000\\000\\361\\020\\000\\000\\230\\023\\000\\000\\243\\026\\000\\000<\\032\\000\\000\\362\\003\\000\\000\\320\\036\\000\\000\\326\\007\\000\\000^,\\000\\000\\362\\n\\000\\000\\314\\007\\000\\000\\030\\004\\000\\000\\207]\\000\\0006\\010\\000\\000\\363\\010\\000\\000\\362\\003\\000\\000D\\t\\000\\000\\315\\007\\000\\000\\314\\007\\000\\000\\254\\n\\000\\000^\\022\\000\\000X\\010\\000\\000\\316\\007\\000\\000I\\n\\000\\000\\316\\007\\000\\000}d\\000\\000B\\t\\000\\000\\364\\003\\000\\000B2\\010\\t\\022\\004\\022\\002\\010\\005\\\"(\\000\\000\\000\\000\\000\\000\\000\\0002\\000\\000\\000\\000\\000\\000\\000>\\000\\000\\000\\000\\000\\000\\000q\\000\\000\\000\\000\\000\\000\\000\\221\\000\\000\\000\\000\\000\\000\\000B\\234\\t\\010\\t\\022\\005\\022\\003\\010\\222\\001\\\"\\220\\t\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\002\\000\\000\\000\\000\\000\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\004\\000\\000\\000\\000\\000\\000\\000\\005\\000\\000\\000\\000\\000\\000\\000\\006\\000\\000\\000\\000\\000\\000\\000\\007\\000\\000\\000\\000\\000\\000\\000\\010\\000\\000\\000\\000\\000\\000\\000\\t\\000\\000\\000\\000\\000\\000\\000\\n\\000\\000\\000\\000\\000\\000\\000\\013\\000\\000\\000\\000\\000\\000\\000\\014\\000\\000\\000\\000\\000\\000\\000\\r\\000\\000\\000\\000\\000\\000\\000\\016\\000\\000\\000\\000\\000\\000\\000\\017\\000\\000\\000\\000\\000\\000\\000\\021\\000\\000\\000\\000\\000\\000\\000\\022\\000\\000\\000\\000\\000\\000\\000\\023\\000\\000\\000\\000\\000\\000\\000\\024\\000\\000\\000\\000\\000\\000\\000\\025\\000\\000\\000\\000\\000\\000\\000\\030\\000\\000\\000\\000\\000\\000\\000\\031\\000\\000\\000\\000\\000\\000\\000\\032\\000\\000\\000\\000\\000\\000\\000\\033\\000\\000\\000\\000\\000\\000\\000\\034\\000\\000\\000\\000\\000\\000\\000\\035\\000\\000\\000\\000\\000\\000\\000\\036\\000\\000\\000\\000\\000\\000\\000\\037\\000\\000\\000\\000\\000\\000\\000 \\000\\000\\000\\000\\000\\000\\000!\\000\\000\\000\\000\\000\\000\\000#\\000\\000\\000\\000\\000\\000\\000$\\000\\000\\000\\000\\000\\000\\000%\\000\\000\\000\\000\\000\\000\\000&\\000\\000\\000\\000\\000\\000\\000\\'\\000\\000\\000\\000\\000\\000\\000(\\000\\000\\000\\000\\000\\000\\000)\\000\\000\\000\\000\\000\\000\\000*\\000\\000\\000\\000\\000\\000\\000+\\000\\000\\000\\000\\000\\000\\000,\\000\\000\\000\\000\\000\\000\\000-\\000\\000\\000\\000\\000\\000\\000.\\000\\000\\000\\000\\000\\000\\000/\\000\\000\\000\\000\\000\\000\\0000\\000\\000\\000\\000\\000\\000\\0001\\000\\000\\000\\000\\000\\000\\0002\\000\\000\\000\\000\\000\\000\\0003\\000\\000\\000\\000\\000\\000\\0004\\000\\000\\000\\000\\000\\000\\0005\\000\\000\\000\\000\\000\\000\\0006\\000\\000\\000\\000\\000\\000\\0007\\000\\000\\000\\000\\000\\000\\0008\\000\\000\\000\\000\\000\\000\\0009\\000\\000\\000\\000\\000\\000\\000:\\000\\000\\000\\000\\000\\000\\000;\\000\\000\\000\\000\\000\\000\\000<\\000\\000\\000\\000\\000\\000\\000=\\000\\000\\000\\000\\000\\000\\000>\\000\\000\\000\\000\\000\\000\\000?\\000\\000\\000\\000\\000\\000\\000@\\000\\000\\000\\000\\000\\000\\000A\\000\\000\\000\\000\\000\\000\\000B\\000\\000\\000\\000\\000\\000\\000C\\000\\000\\000\\000\\000\\000\\000D\\000\\000\\000\\000\\000\\000\\000E\\000\\000\\000\\000\\000\\000\\000F\\000\\000\\000\\000\\000\\000\\000I\\000\\000\\000\\000\\000\\000\\000J\\000\\000\\000\\000\\000\\000\\000K\\000\\000\\000\\000\\000\\000\\000M\\000\\000\\000\\000\\000\\000\\000N\\000\\000\\000\\000\\000\\000\\000O\\000\\000\\000\\000\\000\\000\\000P\\000\\000\\000\\000\\000\\000\\000Q\\000\\000\\000\\000\\000\\000\\000R\\000\\000\\000\\000\\000\\000\\000S\\000\\000\\000\\000\\000\\000\\000U\\000\\000\\000\\000\\000\\000\\000V\\000\\000\\000\\000\\000\\000\\000W\\000\\000\\000\\000\\000\\000\\000X\\000\\000\\000\\000\\000\\000\\000Y\\000\\000\\000\\000\\000\\000\\000Z\\000\\000\\000\\000\\000\\000\\000[\\000\\000\\000\\000\\000\\000\\000\\\\\\000\\000\\000\\000\\000\\000\\000]\\000\\000\\000\\000\\000\\000\\000^\\000\\000\\000\\000\\000\\000\\000_\\000\\000\\000\\000\\000\\000\\000`\\000\\000\\000\\000\\000\\000\\000a\\000\\000\\000\\000\\000\\000\\000b\\000\\000\\000\\000\\000\\000\\000c\\000\\000\\000\\000\\000\\000\\000d\\000\\000\\000\\000\\000\\000\\000e\\000\\000\\000\\000\\000\\000\\000f\\000\\000\\000\\000\\000\\000\\000g\\000\\000\\000\\000\\000\\000\\000h\\000\\000\\000\\000\\000\\000\\000j\\000\\000\\000\\000\\000\\000\\000k\\000\\000\\000\\000\\000\\000\\000l\\000\\000\\000\\000\\000\\000\\000n\\000\\000\\000\\000\\000\\000\\000o\\000\\000\\000\\000\\000\\000\\000p\\000\\000\\000\\000\\000\\000\\000q\\000\\000\\000\\000\\000\\000\\000r\\000\\000\\000\\000\\000\\000\\000s\\000\\000\\000\\000\\000\\000\\000t\\000\\000\\000\\000\\000\\000\\000v\\000\\000\\000\\000\\000\\000\\000w\\000\\000\\000\\000\\000\\000\\000x\\000\\000\\000\\000\\000\\000\\000y\\000\\000\\000\\000\\000\\000\\000z\\000\\000\\000\\000\\000\\000\\000{\\000\\000\\000\\000\\000\\000\\000|\\000\\000\\000\\000\\000\\000\\000}\\000\\000\\000\\000\\000\\000\\000~\\000\\000\\000\\000\\000\\000\\000\\177\\000\\000\\000\\000\\000\\000\\000\\200\\000\\000\\000\\000\\000\\000\\000\\201\\000\\000\\000\\000\\000\\000\\000\\202\\000\\000\\000\\000\\000\\000\\000\\203\\000\\000\\000\\000\\000\\000\\000\\204\\000\\000\\000\\000\\000\\000\\000\\205\\000\\000\\000\\000\\000\\000\\000\\206\\000\\000\\000\\000\\000\\000\\000\\207\\000\\000\\000\\000\\000\\000\\000\\210\\000\\000\\000\\000\\000\\000\\000\\211\\000\\000\\000\\000\\000\\000\\000\\212\\000\\000\\000\\000\\000\\000\\000\\213\\000\\000\\000\\000\\000\\000\\000\\214\\000\\000\\000\\000\\000\\000\\000\\215\\000\\000\\000\\000\\000\\000\\000\\216\\000\\000\\000\\000\\000\\000\\000\\221\\000\\000\\000\\000\\000\\000\\000\\222\\000\\000\\000\\000\\000\\000\\000\\223\\000\\000\\000\\000\\000\\000\\000\\224\\000\\000\\000\\000\\000\\000\\000\\225\\000\\000\\000\\000\\000\\000\\000\\226\\000\\000\\000\\000\\000\\000\\000\\227\\000\\000\\000\\000\\000\\000\\000\\230\\000\\000\\000\\000\\000\\000\\000\\231\\000\\000\\000\\000\\000\\000\\000\\232\\000\\000\\000\\000\\000\\000\\000\\233\\000\\000\\000\\000\\000\\000\\000\\235\\000\\000\\000\\000\\000\\000\\000\\236\\000\\000\\000\\000\\000\\000\\000\\237\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"summary_tokens_len\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\007\\022\\004\\022\\002\\010\\002B\\032\\010\\003\\022\\004\\022\\002\\010\\004\\\"\\0206\\000\\000\\000\\014\\000\\000\\000:\\000\\000\\000#\\000\\000\\000B\\032\\010\\t\\022\\004\\022\\002\\010\\002\\\"\\020\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/tutorials/load_data/tfrecord\n",
    "for raw_record in raw_dataset.take(1):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9abeef9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_tokens_len': array([b'\\x08\\x07\\x12\\x04\\x12\\x02\\x08\\x02B\\x1a\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x04\"\\x106\\x00\\x00\\x00\\x0c\\x00\\x00\\x00:\\x00\\x00\\x00#\\x00\\x00\\x00B\\x1a\\x08\\t\\x12\\x04\\x12\\x02\\x08\\x02\"\\x10\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04'],\n",
       "       dtype='|S64'),\n",
       " 'summary_sentence_indices': array([b'\\x08\\x07\\x12\\x04\\x12\\x02\\x08\\x02B\\x1a\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x04\"\\x10\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00B\\x1a\\x08\\t\\x12\\x04\\x12\\x02\\x08\\x02\"\\x10\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04'],\n",
       "       dtype='|S64'),\n",
       " 'summary_tokens': array([b'\\x08\\x07\\x12\\x04\\x12\\x02\\x08\\x03B\\x88\\x05\\x08\\x03\\x12\\x05\\x12\\x03\\x08\\x9f\\x01\"\\xfc\\x04\\xfc\\x07\\x00\\x00\\xda\\x07\\x00\\x00:\\x10\\x00\\x00\\xcf\\x07\\x00\\x00\\xcc\\x07\\x00\\x00\\x82\\t\\x00\\x00\\xac\\n\\x00\\x00C\\x11\\x00\\x00\\xf2\\x03\\x00\\x00\\xcc\\x07\\x00\\x00\\xa0\\x08\\x00\\x00\\xed\\x03\\x00\\x00\\x1f\\x04\\x00\\x00\\xe3C\\x00\\x00\\xf2\\x03\\x00\\x00\\xce\\x07\\x00\\x00}d\\x00\\x00\\xf2\\x03\\x00\\x00\\x13\\x16\\x00\\x00\\xd0\\x07\\x00\\x00\\xcc\\x07\\x00\\x00\\x18\\x04\\x00\\x00\\x87]\\x00\\x006\\x08\\x00\\x00\\xf3\\x08\\x00\\x00\\xce\\x07\\x00\\x00-J\\x00\\x00\\xe3\\x07\\x00\\x00\\xf3\\x07\\x00\\x00\\xf3\\x03\\x00\\x00\\xf9\\x07\\x00\\x00F\\x0b\\x00\\x00B\\x08\\x00\\x00\\\\\\r\\x00\\x00a\\t\\x00\\x00\\xf2\\x03\\x00\\x00\\xae\\t\\x00\\x00\\xda\\x07\\x00\\x00\\xff\\x07\\x00\\x00J\\x10\\x00\\x00\\xcd\\x07\\x00\\x00OS\\x00\\x00\\xce\\x07\\x00\\x00\\x98\\x13\\x00\\x00?*\\x00\\x00>\\r\\x00\\x00\\xdd\\x07\\x00\\x00\\x9f\\x13\\x00\\x00\\xd0\\x1e\\x00\\x00\\xd0\\x07\\x00\\x00\\x91\\x17\\x00\\x00\\xcc\\x07\\x00\\x00\\xa6\\x12\\x00\\x00\\xf4\\x03\\x00\\x00\\xbc\\x08\\x00\\x00--\\x00\\x00i\\x08\\x00\\x00g\\x11\\x00\\x00\\x1c\\n\\x00\\x00\\xcc\\x07\\x00\\x00\\xac\\n\\x00\\x00C\\x11\\x00\\x00X\\x08\\x00\\x00\\xd5\\x07\\x00\\x00Y\\t\\x00\\x00\\xf4\\x03\\x00\\x00\\xb1\\x10\\x00\\x00\\xd7\\x07\\x00\\x00\\xff\\x07\\x00\\x00\\xed\\x1d\\x00\\x00B/\\x00\\x00p$\\x00\\x00\\xdf\\x07\\x00\\x00\\xf2\\x03\\x00\\x00\\r\\x04\\x00\\x00\\x04*\\x00\\x00\\xe5\\x15\\x00\\x00\\xf2\\x03\\x00\\x00\\xce\\x07\\x00\\x00\\x00\\x08\\x00\\x00\\xff\\x07\\x00\\x00\\xb0:\\x00\\x00\\xee\\x03\\x00\\x00\\xd3\\n\\x00\\x00\\x11)\\x00\\x00\\xf2\\x03\\x00\\x00\\r\\x04\\x00\\x00lX\\x00\\x00\\xf2\\x03\\x00\\x00\\xce\\x07\\x00\\x00\\xa1Z\\x00\\x00\\xf2\\x03\\x00\\x00\\r\\x04\\x00\\x00;\\x0f\\x00\\x00\\xef\\x03\\x00\\x00\\xf2\\x03\\x00\\x00\\xcc\\x07\\x00\\x00\\xac\\n\\x00\\x00C\\x11\\x00\\x00X\\x08\\x00\\x00\\xa8\\x11\\x00\\x00\\xf9\\x07\\x00\\x00\\xd0\\x07\\x00\\x00I\\x1b\\x00\\x00\\\\\\r\\x00\\x00a\\t\\x00\\x00\\xdb\\x07\\x00\\x00v&\\x00\\x00\\xce\\x07\\x00\\x00}d\\x00\\x00\\xed\\x03\\x00\\x00\\x1f\\x04\\x00\\x00\\xbd\\n\\x00\\x00\\x1d\\x08\\x00\\x00\\xeb\\x07\\x00\\x00\\x10\\x08\\x00\\x00\\xcf\\x07\\x00\\x00ur\\x00\\x00[\\x10\\x00\\x00\\xd5\\x0f\\x00\\x00\\xd6\\x07\\x00\\x00\\xcc\\x07\\x00\\x00\\xa6\\x12\\x00\\x00\\xf4\\x03\\x00\\x00\\xc7\\x08\\x00\\x00\\xcc\\x07\\x00\\x00N\\x08\\x00\\x00\\xf2\\x03\\x00\\x00\\xac\\n\\x00\\x00C\\x11\\x00\\x00\\x8a\\t\\x00\\x00\\xf4\\x07\\x00\\x00\\xf1\\x10\\x00\\x00\\x98\\x13\\x00\\x00\\xa3\\x16\\x00\\x00<\\x1a\\x00\\x00\\xf2\\x03\\x00\\x00\\xd0\\x1e\\x00\\x00\\xd6\\x07\\x00\\x00^,\\x00\\x00\\xf2\\n\\x00\\x00\\xcc\\x07\\x00\\x00\\x18\\x04\\x00\\x00\\x87]\\x00\\x006\\x08\\x00\\x00\\xf3\\x08\\x00\\x00\\xf2\\x03\\x00\\x00D\\t\\x00\\x00\\xcd\\x07\\x00\\x00\\xcc\\x07\\x00\\x00\\xac\\n\\x00\\x00^\\x12\\x00\\x00X\\x08\\x00\\x00\\xce\\x07\\x00\\x00I\\n\\x00\\x00\\xce\\x07\\x00\\x00}d\\x00\\x00B\\t\\x00\\x00\\xf4\\x03\\x00\\x00B2\\x08\\t\\x12\\x04\\x12\\x02\\x08\\x05\"(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x002\\x00\\x00\\x00\\x00\\x00\\x00\\x00>\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x91\\x00\\x00\\x00\\x00\\x00\\x00\\x00B\\x9c\\t\\x08\\t\\x12\\x05\\x12\\x03\\x08\\x92\\x01\"\\x90\\t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\r\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x11\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x13\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1f\\x00\\x00\\x00\\x00\\x00\\x00\\x00 \\x00\\x00\\x00\\x00\\x00\\x00\\x00!\\x00\\x00\\x00\\x00\\x00\\x00\\x00#\\x00\\x00\\x00\\x00\\x00\\x00\\x00$\\x00\\x00\\x00\\x00\\x00\\x00\\x00%\\x00\\x00\\x00\\x00\\x00\\x00\\x00&\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\'\\x00\\x00\\x00\\x00\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00)\\x00\\x00\\x00\\x00\\x00\\x00\\x00*\\x00\\x00\\x00\\x00\\x00\\x00\\x00+\\x00\\x00\\x00\\x00\\x00\\x00\\x00,\\x00\\x00\\x00\\x00\\x00\\x00\\x00-\\x00\\x00\\x00\\x00\\x00\\x00\\x00.\\x00\\x00\\x00\\x00\\x00\\x00\\x00/\\x00\\x00\\x00\\x00\\x00\\x00\\x000\\x00\\x00\\x00\\x00\\x00\\x00\\x001\\x00\\x00\\x00\\x00\\x00\\x00\\x002\\x00\\x00\\x00\\x00\\x00\\x00\\x003\\x00\\x00\\x00\\x00\\x00\\x00\\x004\\x00\\x00\\x00\\x00\\x00\\x00\\x005\\x00\\x00\\x00\\x00\\x00\\x00\\x006\\x00\\x00\\x00\\x00\\x00\\x00\\x007\\x00\\x00\\x00\\x00\\x00\\x00\\x008\\x00\\x00\\x00\\x00\\x00\\x00\\x009\\x00\\x00\\x00\\x00\\x00\\x00\\x00:\\x00\\x00\\x00\\x00\\x00\\x00\\x00;\\x00\\x00\\x00\\x00\\x00\\x00\\x00<\\x00\\x00\\x00\\x00\\x00\\x00\\x00=\\x00\\x00\\x00\\x00\\x00\\x00\\x00>\\x00\\x00\\x00\\x00\\x00\\x00\\x00?\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x00A\\x00\\x00\\x00\\x00\\x00\\x00\\x00B\\x00\\x00\\x00\\x00\\x00\\x00\\x00C\\x00\\x00\\x00\\x00\\x00\\x00\\x00D\\x00\\x00\\x00\\x00\\x00\\x00\\x00E\\x00\\x00\\x00\\x00\\x00\\x00\\x00F\\x00\\x00\\x00\\x00\\x00\\x00\\x00I\\x00\\x00\\x00\\x00\\x00\\x00\\x00J\\x00\\x00\\x00\\x00\\x00\\x00\\x00K\\x00\\x00\\x00\\x00\\x00\\x00\\x00M\\x00\\x00\\x00\\x00\\x00\\x00\\x00N\\x00\\x00\\x00\\x00\\x00\\x00\\x00O\\x00\\x00\\x00\\x00\\x00\\x00\\x00P\\x00\\x00\\x00\\x00\\x00\\x00\\x00Q\\x00\\x00\\x00\\x00\\x00\\x00\\x00R\\x00\\x00\\x00\\x00\\x00\\x00\\x00S\\x00\\x00\\x00\\x00\\x00\\x00\\x00U\\x00\\x00\\x00\\x00\\x00\\x00\\x00V\\x00\\x00\\x00\\x00\\x00\\x00\\x00W\\x00\\x00\\x00\\x00\\x00\\x00\\x00X\\x00\\x00\\x00\\x00\\x00\\x00\\x00Y\\x00\\x00\\x00\\x00\\x00\\x00\\x00Z\\x00\\x00\\x00\\x00\\x00\\x00\\x00[\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\\\\\x00\\x00\\x00\\x00\\x00\\x00\\x00]\\x00\\x00\\x00\\x00\\x00\\x00\\x00^\\x00\\x00\\x00\\x00\\x00\\x00\\x00_\\x00\\x00\\x00\\x00\\x00\\x00\\x00`\\x00\\x00\\x00\\x00\\x00\\x00\\x00a\\x00\\x00\\x00\\x00\\x00\\x00\\x00b\\x00\\x00\\x00\\x00\\x00\\x00\\x00c\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x00\\x00\\x00\\x00\\x00\\x00\\x00e\\x00\\x00\\x00\\x00\\x00\\x00\\x00f\\x00\\x00\\x00\\x00\\x00\\x00\\x00g\\x00\\x00\\x00\\x00\\x00\\x00\\x00h\\x00\\x00\\x00\\x00\\x00\\x00\\x00j\\x00\\x00\\x00\\x00\\x00\\x00\\x00k\\x00\\x00\\x00\\x00\\x00\\x00\\x00l\\x00\\x00\\x00\\x00\\x00\\x00\\x00n\\x00\\x00\\x00\\x00\\x00\\x00\\x00o\\x00\\x00\\x00\\x00\\x00\\x00\\x00p\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\x00\\x00\\x00\\x00\\x00\\x00\\x00r\\x00\\x00\\x00\\x00\\x00\\x00\\x00s\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00v\\x00\\x00\\x00\\x00\\x00\\x00\\x00w\\x00\\x00\\x00\\x00\\x00\\x00\\x00x\\x00\\x00\\x00\\x00\\x00\\x00\\x00y\\x00\\x00\\x00\\x00\\x00\\x00\\x00z\\x00\\x00\\x00\\x00\\x00\\x00\\x00{\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x00\\x00\\x00\\x00\\x00\\x00\\x00~\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x7f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x81\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x82\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x83\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x84\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x85\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x86\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x87\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x88\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x89\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x91\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x92\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x93\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x95\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x96\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x97\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x98\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x99\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x9a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x9b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x9d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x9e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x9f'],\n",
       "       dtype='|S1894'),\n",
       " 'summary_num_sentences': array([54, 12, 58, 35]),\n",
       " 'label': array([20]),\n",
       " 'summary': array([b\"After his defeat in the original Star Fox, the game's antagonist, Andross, returns to the Lylat system and launches an all-out attack against Corneria, using his new fleet of battleships and giant missiles launched from hidden bases to destroy the planet. General Pepper again calls upon the Star Fox team for help. Armed with new custom Arwings, a Mothership, and two new recruits (Miyu, a lynx, and Fay, a dog), the Star Fox team sets out to defend Corneria by destroying Andross's forces before they can inflict critical damage on the planet. Along the way, Star Fox must also combat giant boss enemies, bases on planets throughout the Lylat system, members of the Star Wolf team and finally Andross himself.\"],\n",
       "       dtype='|S711')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.tensorflow.org/tutorials/load_data/tfrecord\n",
    "result = {}\n",
    "# example.features.feature is the dictionary\n",
    "for key, feature in example.features.feature.items():\n",
    "    # The values are the Feature objects which contain a `kind` which contains:\n",
    "    # one of three fields: bytes_list, float_list, int64_list\n",
    "\n",
    "    kind = feature.WhichOneof(\"kind\")\n",
    "    result[key] = np.array(getattr(feature, kind).value)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bde008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 08:59:05.354274: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354305: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354326: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354353: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354367: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354382: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354406: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354439: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354455: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354477: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354503: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354521: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354548: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354597: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354649: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354666: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n",
      "2021-12-16 08:59:05.354695: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at example_parsing_ops.cc:94 : Invalid argument: Key: summary_num_sentences.  Can't parse serialized Example.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Key: summary_num_sentences.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z_/d29z43w90kz6f4kbzv5c9m9r0000gn/T/ipykernel_50164/493463994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mraw_dataset_mapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_single_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_descriptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# raw_dataset_mapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparsed_record\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_dataset_mapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/.virtualenvs/tf/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Key: summary_num_sentences.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "raw_dataset_mapped = raw_dataset.map(lambda x: tf.io.parse_single_example(x, feature_descriptions))\n",
    "# raw_dataset_mapped\n",
    "for parsed_record in raw_dataset_mapped.take(10):\n",
    "    print(repr(parsed_record))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
